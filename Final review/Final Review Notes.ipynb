{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6723d4e0-b912-47f9-94e9-e366e6c4b834",
   "metadata": {},
   "source": [
    "<h1>Final Review “Cheat Sheet”</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd1343-5662-46d3-9c1c-c73f8dc185af",
   "metadata": {},
   "source": [
    "**Chapter 1\n",
    "R and tidyverse**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2697d53-31f4-453c-9129-65ff897213ee",
   "metadata": {},
   "source": [
    "**LO1: Identify the different types of data analysis questions and categorize a question into the correct type:**\n",
    "\n",
    "Different types of questions:\n",
    "\n",
    "**Descriptive**: asks about summarized characteristics of a data set without interpretation. Ask what is, rather than why and how. \n",
    "Ex: how many languages are there in India?\n",
    "\n",
    "**Exploratory**: asks if there are trends, relationships within a single data set. \n",
    "Ex: does exam success rate change with the amount of sleep students get?\n",
    "\n",
    "**Predictive**: asks about predicting measurements for things or people. FOCUS on what things predict the outcome, NOT what causes the outcome. Classify new observations based on existing data.\n",
    "Ex: what is the type of a newly observed tumour based on its width and texture?\n",
    "\n",
    "**Inferential**: looks for patterns, relationships in a single data set AND makes inference on the wider population.\n",
    "Ex: does sleep times affect the success rate of students in all of Canada?\n",
    "\n",
    "**Causal**: asks about whether changing one factor will lead to change in another factor, in the wider population. \n",
    "Ex: does sleep deprivation lead to lower success rate in students in BC?\n",
    "\n",
    "**Mechanistic**: asks about the underlying mechanism of the observed relationships. How does it happen?\n",
    "Ex: How does sleep deprivation lead to lower success rates in students of BC?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d33d01-27fa-4cca-8ca7-a49f5a8a89f7",
   "metadata": {},
   "source": [
    "**LO2: Load the tidyverse package into R**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f809fd7-88b7-4c49-9fa7-b50cad3a7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows = 6)\n",
    "library(palmerpenguins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d6c83-2996-49d7-a4ed-2d9cca1aa1d5",
   "metadata": {},
   "source": [
    "**Function**: a function is a special word in R, takes instructions(arguments) and does something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345d60f-1928-47fa-801e-9d8bbc3ff49a",
   "metadata": {},
   "source": [
    "**R package**: a collection of functions that can be used additional to the built-in R package functions. **ex**: read_csv() is a function contained in tidyverse package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afe5b413-dedb-432f-a046-244689c5cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code# \n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2b426-ce1f-4d4d-9339-0a3fd79f8fb0",
   "metadata": {},
   "source": [
    "**Tidyverse**: this is a meta package contains many functions such as those used to load, clean, wrangle, and visualize data. It also contains several other packages as well (meta package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88b1603f-9734-4ce6-859e-f8f88b7bc8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to put quotes \"\" around file names and other words in the code cell to distuiguish\n",
    "# them from special words(like function) for R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd466a-686c-4317-89c1-9f3396ba372c",
   "metadata": {},
   "source": [
    "**LO3: read tabular data with read_csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab687486-5465-4771-ade4-a2c40aa88b5c",
   "metadata": {},
   "source": [
    ".csv: tubular data in the \"comma-separated values\" format, each value in the table separated by a comma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d457af-425b-4f2c-9651-96b27d4a3e78",
   "metadata": {},
   "source": [
    "**read_csv:** funcion, expects data files to:\n",
    "have column names (headers)\n",
    "use a comma (,) to separae columns\n",
    "does not have row names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01838faf-6ed7-42d0-b331-a6b65e001752",
   "metadata": {},
   "outputs": [],
   "source": [
    "##code:\n",
    "## name <- read_csv(\"folder name/data file name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb166077-127c-4e7b-bb03-bc2172f12cfb",
   "metadata": {},
   "source": [
    "**LO4: naming things in R**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b43a7b7-adf8-4644-b1f5-66a1cd546875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the assignment symbol \"<-\"\n",
    "my_number <- 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8af1182a-bca8-403b-97c8-3d95787d797b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5"
      ],
      "text/latex": [
       "5"
      ],
      "text/markdown": [
       "5"
      ],
      "text/plain": [
       "[1] 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_number + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e1a70-3aba-402f-835f-cf7761f7621e",
   "metadata": {},
   "source": [
    "**Conventions**: when naming, only use lowercase letters, numbers and _ to separate words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9454f5e9-0e42-4389-a5e9-1b514d791742",
   "metadata": {},
   "source": [
    "**LO5: create and organize subsets of tabular data using filter, select, arrange, and slice**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47efa3a2-0fb5-46bd-a034-7876699190c7",
   "metadata": {},
   "source": [
    "**filter**: obtain a smaller set of rows with specific values (ex: only want rows with the year 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f0d3f-de28-40e6-8268-1f8bfd9a601e",
   "metadata": {},
   "source": [
    "**select**: obtain a smaller set of columns (ex: only want year and pollutants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c8de0-d268-44ef-b349-e903b86e4af2",
   "metadata": {},
   "source": [
    "**code for filter**: filter(name of data, year==\"2022\")\n",
    "\n",
    "logical statement: the secod argument in the function, evaluates to TRUE or FALSE, in filter, it evaluates to TRUE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80913d-0e3a-4fae-b176-9319d9c6331d",
   "metadata": {},
   "source": [
    "\" \" is used to tell R this is a **string** value, not a special word in the R language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f730b6-4030-4793-b1f5-384a7fe72c75",
   "metadata": {},
   "source": [
    "**code for select**: select(data name, column1, column2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70d6e6a-bd6f-4800-9bdd-92eed863be99",
   "metadata": {},
   "source": [
    "**arrange**: **order the rows** of data frame by **values of a particular column**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96246043-55e8-4e89-8084-5bcd6c17364b",
   "metadata": {},
   "source": [
    "**code for arrange**: arrange(dataframe, by=desc(column))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717032b9-f00c-4665-9e14-e32d5cce752e",
   "metadata": {},
   "source": [
    "-Descending: (desc()), from largest to smallest\n",
    "\n",
    "**arrange function automatically orders rows in ascending**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f451a-3fad-4576-9d57-0bc09e1261af",
   "metadata": {},
   "source": [
    "**slice**: function which selects rows according to **row number**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c9e60-5735-4a08-944e-f609da7fbcc5",
   "metadata": {},
   "source": [
    "**code for slice**: slice(dataframe, 1:10)\n",
    "\n",
    "-the second argument tells R the raws to keep is from 1 to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f8398-4da8-43f0-8ba8-4ec4bfea5d57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f817a03a-e8d3-4d1e-8997-621169c6c642",
   "metadata": {},
   "source": [
    "**LO6: add and modify columns in tabular data using mutate**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02478b2-5476-4718-abfe-ecf5d312317e",
   "metadata": {},
   "source": [
    "**mutate**: perform a calculation, making use of existing columns to compute a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f69d5bc-b43c-4c54-9cc4-6fa3558e45b9",
   "metadata": {},
   "source": [
    "**code for mutate**: mutate(dataframe, new column name = the equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0f37ad-9e55-4f84-86c6-cd5b25466fb9",
   "metadata": {},
   "source": [
    "col_double means that the data in this column is a number-type, specifically real numbers (meaning that these values can contain decimals)\n",
    "\n",
    "col_integer means that the data in this column is integers (whole numbers)\n",
    "\n",
    "col_character means that the data in this column contains text (e.g., letter or words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e014ad-7c34-47c0-8068-1cf95ede57fe",
   "metadata": {},
   "source": [
    "**LO7: visualize data with a ggplot bar plot**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94afc09d-2149-492c-b5f7-3cbafe9ffda4",
   "metadata": {},
   "source": [
    "**Benefits of visualization**: great tool for summarizing information, help effectively communicate with audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "240c968a-ca0e-4906-93b8-e2240a679666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtag provide comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c42cb-0772-44d6-a254-f83bc483f2c1",
   "metadata": {},
   "source": [
    "?filter\n",
    "\n",
    "this is a way to pull up the documentation for most functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7867b-9630-4482-b365-26de68708c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa913552-ab00-4415-a859-d2681d1254b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f3a8e8c-e1f0-46d9-858c-011a2ef9033f",
   "metadata": {},
   "source": [
    "**Chapter 2 (reading in data locally and from the web)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70164148-659c-48fe-b65b-16a3367211fa",
   "metadata": {},
   "source": [
    "**Important packages for chapter 2**\n",
    "\n",
    "- readxl: provides the read_excel() function to load sheet from excel file into R\n",
    "- DBI: provides dbConnect() function to connect SQLite database. provides dbListTables() function to list the tables in a database\n",
    "- dbplyr: provides tbl() function to help create a reference to a database table searchable. provides collect() to retrieve data from a database query and bring it to R\n",
    "- RPostgres: allows us to work on PostgreSQL databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440aa768-5acd-4797-a165-c1799118c8b3",
   "metadata": {},
   "source": [
    "**LO1: Define the types of path and use them to locate files**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919c2c8-5f26-4641-af42-0fa697020c84",
   "metadata": {},
   "source": [
    "- a file could live local(computer), or remoate (internet), different paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf6e7a-5235-4f7b-8aa8-7c0a7b3448af",
   "metadata": {},
   "source": [
    "**1. Relative file path**: where the file is with respect to the folder (**working directory**) currently in, on the computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1101cd4-5e65-4ade-947f-5f6d80b124ed",
   "metadata": {},
   "source": [
    "**2. Absolute file path**: file with respect to the base (root) folder of computer's firesystem, regardless of where you are working.\n",
    "\n",
    "- **Always start with \"/\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6729adf-ba81-4efb-97cd-ad9836042cbd",
   "metadata": {},
   "source": [
    "**\" . \" means reach a file from current directory (folder)**\n",
    "\n",
    "**\" .. \" means go back to previous directory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78225d9-2826-45cb-a334-8f206488f7c4",
   "metadata": {},
   "source": [
    "**Generally**, it is better to use relative paths. B/C it helps ensure the code can be run on a different computer, and is shorter and easier to write. (able to run on different computer as the path is same on any, but for absolute, depending on the name the person gave to the root folders, may be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d816e1-b672-4442-9127-1f4750527111",
   "metadata": {},
   "source": [
    "**LO2: read data into R from various types of path using following functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d0d4f-5206-4979-81d8-a178fb6fe581",
   "metadata": {},
   "source": [
    "Plain text file: a document containing only text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411dcc92-1f63-46c9-a4b6-cbaeaf3ecde0",
   "metadata": {},
   "source": [
    "**1. read_csv**: for reading tabular data with comma separated values\n",
    "- the delimeter(separator): \",\"\n",
    "\n",
    "code: canlang_data <- read_csv(\"data/can_lang.csv\")\n",
    "- data/ is put before file's name because the data set is located in a sub-folder called data, relative to where we are running our R code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f182d-2274-43cd-b305-31d19a771638",
   "metadata": {},
   "source": [
    "**skipping rows when reading data** : There sometimes may be extra informations about the data included at the top of data file(metadata). NO delimeters. BUT not intended to be read into a data frame cell with the tabular data.\n",
    "\n",
    "- in this case, use skip argument: read_csv(\"data/name\", skip=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4818ab1-01aa-4036-93cb-a37bd40fbb71",
   "metadata": {},
   "source": [
    "**2. read_tsv**: tsv=tab-separated values files. \n",
    "\n",
    "code: read_tsv(\"data/can_lang.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af3e62-a3d0-4546-80d0-f2718a5c4144",
   "metadata": {},
   "source": [
    "**3. read_delim**: a more general function, including read_csv, read_tsv which are special cases. NEED to specify a **delimeter**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a19419-7409-4c3c-8f69-1ba38825fe0b",
   "metadata": {},
   "source": [
    "- delim = \"\\t\" is for tab-separated values file\n",
    "- delim = \", \" is for comma-separated values file\n",
    "- delim = \" ; \" is for semicolon-separated values file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a713ff-191d-42dc-a541-3395e3f9e32a",
   "metadata": {},
   "source": [
    "**data frames need to have column names**: use argument col_names= \" \", \" \" is an option\n",
    "use function rename(data, **new_name=old_name**, column2= X2) is also an option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32e74a-2f9e-4956-800a-5cbc4d1f2df6",
   "metadata": {},
   "source": [
    "**4. a)read tabular data directly from URL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7291b40-95f7-4050-a9d9-7d74dd6c0f84",
   "metadata": {},
   "source": [
    "(URL): Uniform Resource Locator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0fc3a-1fa7-468b-9be7-ecfb1b37f5dd",
   "metadata": {},
   "source": [
    "**code**: url <- \"https://raw.githubusercontent.com/UBC-DSCI/data/main/can_lang.csv\"\n",
    "\n",
    "canlang_data <- read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117a3d2-5f40-4506-a0c7-de1e9fd8029b",
   "metadata": {},
   "source": [
    "**4. b)downloading data from a URL**\n",
    "\n",
    "for URL that are not nicely formatted to directly use any functions\n",
    "\n",
    "**code**: url <- \"https....\"\n",
    "\n",
    "download.file(url,\"data/can_lang.csv\")\n",
    "\n",
    "2nd argument is the path to store the downloaded file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e7bec-b6fe-4aec-9ebd-817d08a796e6",
   "metadata": {},
   "source": [
    "**5. reading tabular data from Microsoft Excel file**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ae57c-0c5b-4f99-bc32-6570f4ec6d27",
   "metadata": {},
   "source": [
    "- the file name extension is .xlsx\n",
    "- this is not a plain text file\n",
    "- use library(readxl)\n",
    "- use function read_excel()\n",
    "- use sheet argument to specify the sheet number or name\n",
    "- use range argument to specify cell ranges (for when single sheet contains multiple tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929633ff-7d39-40b5-ac4d-ce73fee73da4",
   "metadata": {},
   "source": [
    "**why should we always explore the data file before importing into R**\n",
    "\n",
    "- helps me decide which function and arguments I will need to load the data into R successfuly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a392c-6d93-4763-95c2-1c55c217b744",
   "metadata": {},
   "source": [
    "**6. reading data from a database**\n",
    "\n",
    "**database**: a type to data storage -> almost all database management systems employ SQL (strcutured query language) to obtain data from database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaa84cc-b9ec-4980-990d-86660a305b84",
   "metadata": {},
   "source": [
    "a) SQLite database are usually stored and accessed locally on one computer from a file with a .db extension or .sqlite extension.\n",
    "\n",
    "- NOT plain text files, CANNOT be read in a plain text editor\n",
    "1. connect R to the database using dbConnect() function from DBI package\n",
    "- dbConnect() opens up a communication channel that R can use to send SQL commands to database\n",
    "\n",
    "**library(DBI)\n",
    "canlang_conn <- dbConnect(RSQLite::SQLite(), \"data/can_lang.db\")**\n",
    "\n",
    "- can use dbListTables(connect database) to list the table names in the database\n",
    "\n",
    "2. **tbl(canlang_conn, \"lang\")** function allows us to reference this table so we can perform operations and work with data stored in databases as if they were just regular data frames WITHOUT having to store all its data in R's memory.\n",
    "3. head() function allows us to see the first few rows of a dataset\n",
    "4. use **collect** function to download the transformed data from the database and store it in a dataframe.\n",
    "5. write data from R to a .csv file: use write_csv(the collected dataframe, \"data/newname.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd086335-9056-4287-9864-9efa3de06728",
   "metadata": {},
   "source": [
    "**Reading data from a PostgreSQL database**\n",
    "\n",
    "- designed to be used and accessed on a network -> have to provide more information to R when connecting to Postgres databases\n",
    "\n",
    "Example: \n",
    "\n",
    "library(RPostgres)\n",
    "\n",
    "***canmov_conn <- dbConnect(RPostgres::Postgre(), dbname = \"can_mov_db\",\n",
    "                        host = \"fakeserver.stat.ubc.ca\", port= 5432, user = \"user0001\",       password = \"abc123\")***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e232efd-ead5-41a6-a3ea-e3433d719ed4",
   "metadata": {},
   "source": [
    "**Advantages of database:**\n",
    "1. allow storing large data set across multiple computers with backups\n",
    "2. Allow multiple users to access them simultaneously and remotely without conflicts and errors\n",
    "3. provide mechanisms for ensuring data integrity and validating input\n",
    "4. provide security to keep data safe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705ee7e-b6f8-4982-a688-a4e9104f5617",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d230c-597a-4e43-888c-742a8d6c9caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61fb9fc4-d747-45d0-8ab3-882fadcbd685",
   "metadata": {},
   "source": [
    "**Chapter 3 (Data Wrangling)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e737733-e49b-4ee7-83d2-60a8556427f9",
   "metadata": {},
   "source": [
    "**Important Packages for Chapter 3**\n",
    "\n",
    "- dplyr: part of tidyverse metapackage (if loaded tidyverse, then do not need to load this)\n",
    "\n",
    "  ->provides functions like (select, filter, mutate, arrange, summarize, and group_by)\n",
    "- purrr: part of the tidyverse metapackage.\n",
    "- allows us to use the map() and map_df() functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5cc8bd-59fa-4991-8de4-95b90ef82dda",
   "metadata": {},
   "source": [
    "**LO1: define the term \"tidy data\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6808bc-2ecb-4db0-aaa7-0b6fdb6c8f18",
   "metadata": {},
   "source": [
    "**Criteria for Tidy Data!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84a207-749c-4e06-8f5b-c8d05fde781f",
   "metadata": {},
   "source": [
    "1. Each row is a single observation\n",
    "2. Each column is a single variable\n",
    "3. Each value is a single cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d2183a-cece-425e-9690-b70adb3b1287",
   "metadata": {},
   "source": [
    "**LO2: discuss the advantages of storing data in a tidy data format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361410d2-d4b2-498d-b3fb-bfc2acabf16c",
   "metadata": {},
   "source": [
    "- tidy data is a single, consistent format that almost every function in tidyverse recognizes, making it easy to manipulate, plot, and analyze using the same tools.\n",
    "- tidy data is easier for human to interpret.\n",
    "- Untidy data require more complex code that are easy to have errors and hard for others to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36820d6f-ad2d-41ea-a39b-bfaafd2f566e",
   "metadata": {},
   "source": [
    "**LO3: define what vectors, lists, and data frames are in R, and describe how they relate to each other**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56727db3-0373-4832-a406-5e3ce4201301",
   "metadata": {},
   "source": [
    "**data frame**: table-like structure for storing data in R. (stores observations, variables and their values)\n",
    "\n",
    "- variable: a characteristic, number, or quantity that can be measured\n",
    "- observation: all of the measurements for a given entity\n",
    "- value: a single measurement of a single variable for a given entity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de43e4f-dc22-487d-8a2d-9bbb35dec038",
   "metadata": {},
   "source": [
    "**what is a vector?**\n",
    "\n",
    "- vectors are objects that can contain one or more elements that MUST ALL BE THE SAME DATA TYPE\n",
    "- you can use c() function to create vectors in R: vector_name <- c(\"200\", \"300\", \"400\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42768657-924f-4260-82d1-93686c34517b",
   "metadata": {},
   "source": [
    "**what is a list?**\n",
    "\n",
    "- Lists are also objects with multiple, ordered elements, BUT the elements in a list **DO NOT** have to be the **same type**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9351a1-2fca-4444-b896-9fc7cb2e9480",
   "metadata": {},
   "source": [
    "**data frames**: is just a special kind of list:\n",
    "\n",
    "- each element itself must either be a vector or a list\n",
    "- each element (vector or list) must have the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348572a6-05b9-4000-ad60-91f9d3ad8665",
   "metadata": {},
   "source": [
    "**Tibbles are special kind of data frames that more enhanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6392a67-e0af-4268-814d-fa3d6575f14d",
   "metadata": {},
   "source": [
    "**LO4: describe the common types of data in R and their uses**\n",
    "\n",
    "**Data Type**\n",
    "\n",
    "- **character: (chr)**, letters or numbers surrounded by quotes, ex: \"1\", \"world\"\n",
    "- **double (dbl)**, numbers with decimal values, ex: 1.2333\n",
    "- **integer (int)**, whole numbers, no decimals, ex: 1L,20L (\"L\" tells R to store it as int)\n",
    "- **logical (lgl)**, either true or false, ex: TRUE, FALSE\n",
    "- **factor (fct)**, used to represent data with a limited number of values(usually categories), ex: color(**categorical**) variable **with levels** red, green, orange. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785accc-abb0-4444-9f08-0daec73d7ae7",
   "metadata": {},
   "source": [
    "**Even though factors sometimes **look** like characters, they are not used to represent text, words, names, and paths in the way characters are. Factors help us encode variables that represent **categories** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078d824-b0e3-4d48-aa39-cf4a0805a3d3",
   "metadata": {},
   "source": [
    "**LO5: Use the following functions for their intended data wrangling tasks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0625ef06-4f5f-4a53-85d6-304c97b88974",
   "metadata": {},
   "source": [
    "**1. pivot_longer**\n",
    "\n",
    "- combines columns, making data frame longer and narrower.\n",
    "- **combine** columns that are really part of the **same variable** but currently stored in separated columns.\n",
    "\n",
    "pivot_longer(dataframe,\n",
    "            cols= columns to combine,\n",
    "            names_to= \"new column 1\",\n",
    "            values_to= \"new column 2\")\n",
    "\n",
    "- input for 1st argument is the data frame\n",
    "- input for 2nd argument are the names of the columns we want to combine into a single column\n",
    "- input for 3rd: the new column1 that will be created, values come from the **names** of the columns that we want to combine\n",
    "- input for 4th: the new column2 that will be created, values will come from the **values** of the combines columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567b7f6-b76d-4078-8984-29e3a22b1dd5",
   "metadata": {},
   "source": [
    "**2. pivot_wider**\n",
    "\n",
    "- if there's one type of observation spread across multiple rows rather than a single row\n",
    "- use pivot_wider to increase the number of columns and decrease the number of rows\n",
    "\n",
    "pivot_wider(data frame,\n",
    "            names_from = col_name_1,\n",
    "            values_from = col_name_2)\n",
    "\n",
    "- input 1st for the dataframe\n",
    "- input 2nd is **the column** that the **names** of the new columns take from\n",
    "- input 3rd is **the column's values** that the **values** of the new columns take from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae0c816-1e76-4ecd-8c5a-41197326e2af",
   "metadata": {},
   "source": [
    "**3. separate**\n",
    "\n",
    "- use this to deal with multiple delimeters (multiple values stored in the same cell)\n",
    "\n",
    "separate(dataframe,\n",
    "    col= col_name,\n",
    "    into = c(\"col_name1\", \"col_name2\"),\n",
    "    sep = \"/\")\n",
    "\n",
    "  1. specify the column we want to split\n",
    "  2. a character vector of the new column names we would like the split columns to have\n",
    "  3. the separator on which to split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd33c1e-74ea-48f1-b034-d772b7cbc10c",
   "metadata": {},
   "source": [
    "**4. select**\n",
    "\n",
    "- use to extract a range of columns\n",
    "- if simply typing all of the column names needed to select may be time-consuming. **instead**, use a \"select helper\"\n",
    "  \n",
    "**select helpers**: **operators** that make it easier for us to select columns\n",
    "\n",
    "ex: to chose a range of columns, use **(:)** to denote the range. \n",
    "\n",
    "ex: select(dataframe, starts_with(\" \")) **(starts_with())** is a select helper to choose columns with names start with a particular word or letter.\n",
    "\n",
    "ex: select(dataframe, contains(\"_\")), **contains()** is a select helper to choose column names that contain a particular thing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b8f4d-cd0d-4fec-a443-87920fd21f4f",
   "metadata": {},
   "source": [
    "**5. filter**\n",
    "\n",
    "- use filter to extract rows where logical statement evaluates to TRUE.\n",
    "\n",
    "ex: extracting rows that have a certain value with ==, filter(dataframe, column == \"value\")\n",
    "\n",
    "ex: extracting rows that do not have a certain value with !=, filter(dataframe, column != \"value\")\n",
    "\n",
    "ex: extracting rows satisfying multiple conditions using (,) or (&), \n",
    "\n",
    "filter(dataframe, colum1 == \"value1\", column2 == \"value2\")\n",
    "\n",
    "ex: extracting rows satisfying **at least one** condition using (|),\n",
    "\n",
    "filter(dataframe, column1 == \"value1\" | column1 == \"value2\")\n",
    "\n",
    "ex: extracting rows with values in a vector using (%in%), \n",
    "\n",
    "similar to using (|), but easier as it is summarized in a vector. \n",
    "**different** from == because == means choosing the values that only match that first element listed. But %in% means R will choose the values that can match any of the elements in the vector.\n",
    "\n",
    "vector_name <- c(\"value1\", \"value2\", \"value3\")\n",
    "filter(dataframe, colum_name %in% vector_name)\n",
    "\n",
    "ex: extracting rows above or below a threshold using > and <\n",
    "\n",
    "filter(dataframe, column > 2345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb64f4-870e-4719-b11f-f690fa533be7",
   "metadata": {},
   "source": [
    "**6. mutate**\n",
    "\n",
    "Ex: using mutate to modify columns\n",
    "\n",
    "mutate(dataframe, new_name = as_factor(column))\n",
    "\n",
    "- in here, we can use mutate to modify the elements in our column into factor.\n",
    "\n",
    "Ex: using mutate to create new columns\n",
    "\n",
    "mutate(dataframe, new_column = operation between old columns or smth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f7903-7d44-46c4-b6d9-d32605066cc4",
   "metadata": {},
   "source": [
    "**7. pipe operator |>**\n",
    "\n",
    "- used to combine functions, results in a **cleaner, and easier to follow code**\n",
    "- takes the output from function on the left and passes it to the first argment to function on the right\n",
    "\n",
    "**reasons why making multiple lines of code and storing temporary objects is not preffered**\n",
    "\n",
    "- difficult for readers to understand\n",
    "- tricks the reader to think the temporary intermediate objects are important\n",
    "- reader has to look through and find where the intermediate objects are used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a206d6d7-d0d4-4443-9b93-b72236ab2fcb",
   "metadata": {},
   "source": [
    "**compose function is also not a good idea**\n",
    "\n",
    "- the functions compose in the opposite order in which they are computed by R\n",
    "- long code makes it difficult for readers to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c79628-ff9d-4af7-8dee-a3525faf186e",
   "metadata": {},
   "source": [
    "**When should we store temporary objects**\n",
    "\n",
    "- store a temperary object before feeding it to plot function, so you can look at the wrangled data before plotting it to make sure there are no errors.\n",
    "- piping many functions can be difficult to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9338ee-2f36-4660-97cb-a1755007de6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99048e9f-ed76-4472-9d93-d36884a63632",
   "metadata": {},
   "source": [
    "**8. summarize**\n",
    "\n",
    "- use summarize to calculate summary statistics:\n",
    "\n",
    "ex: summarize(dataframe, new column name = max(old column))\n",
    "\n",
    "in here, min and max functions can be used to calculate the maximum value from the column specified.\n",
    "\n",
    "**Basic summary functions**\n",
    "\n",
    "- min\n",
    "- max\n",
    "- mean\n",
    "- sum\n",
    "\n",
    "**if there's NA in the column's element:**\n",
    "\n",
    "- add argument na.rm= TRUE into the summary functions to remove the NA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766391c1-71b2-42bb-8e9c-f0ed2445dfe5",
   "metadata": {},
   "source": [
    "**9. group_by() + summarize()**\n",
    "\n",
    "- this combination is used when you want to apply the same function to groups of rows\n",
    "\n",
    "group_by(dataframe, col_names) |>\n",
    "\n",
    "summarize(\n",
    "            min_col_name1 = min(col_name1),\n",
    "            max_col_name2 = max(col_name2),\n",
    "            total_volume = mean(total_volume, na.rm =TRUE))\n",
    "\n",
    "- group_by() takes an existing data set and converts it into a grouped data set where operations are performed \"by group\".\n",
    "- summarize() works analogous to mutate() function, EXCEPT instead of adding columns to an existing data frame, it creates a new data frame. USED to calculate **summary statistics** (max, min, mean) for each group of rows created with group_by()\n",
    "- pairing these functions together can let you summarize values for subgroups within a data set\n",
    "- group_by() creates its own columns and summarize() creates its own columns which then both combine to form a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d902a7-60a5-4347-88e6-cd02601e16d0",
   "metadata": {},
   "source": [
    "**10. summarize() + across ()**\n",
    "\n",
    "- to calculate summary statistics on many columns\n",
    "\n",
    "summarize(across(column1:column4, ~max(.x, na.rm=TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1298d705-89e2-4560-a78b-f8a05bff3c30",
   "metadata": {},
   "source": [
    "**11. map(), map_dfr()**\n",
    "\n",
    "- alternative to summarize+across, for applying function to many columns\n",
    "- map takes two arguments, an object(a vector, data frame or list) and the function that you would like to apply\n",
    "- map() does not give dataframe, it gives list instead\n",
    "- map_dfr() gives data frame, combining row-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc9086-e790-48a0-9216-aa062660fe68",
   "metadata": {},
   "source": [
    "**12. mutate + across**\n",
    "\n",
    "- ex: when converting units of measurements across many columns\n",
    "- or we want to change every value in data from to another data type\n",
    "\n",
    "mutate(across(dataframe, column1:column4, as.integer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3231ede-99e1-4496-878d-6c30932716ec",
   "metadata": {},
   "source": [
    "**13. rowwise + mutate**\n",
    "\n",
    "- apply function across columns but within one row\n",
    "- Ex: we want the max value from different columns in one row (ie find the maximum from values in one row)\n",
    "\n",
    "rowwise(dataframe) |>\n",
    "mutate(maximum= max(c(column1, column2, column3, column4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffd2d10-236a-4ff6-a408-292119b2b96d",
   "metadata": {},
   "source": [
    "**similar to group_by(), rowwise() doesn't appear to do anything when it is called by itself, but we can apply rowwise with other functions to change how these other functions operate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26dc24-71a3-4d9b-9dd7-8ffc058e63a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6c348-5c59-498a-840e-3a9a118d756d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "591486ef-a723-44c4-9d14-22f124d5e95b",
   "metadata": {},
   "source": [
    "**Chapter 4 (Effective data visualization)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9762a4e7-36df-456c-a954-6c0b78d588f7",
   "metadata": {},
   "source": [
    "**Important packages for chapter 4.0**\n",
    "\n",
    "- `ggplot2`\n",
    "  - part of tidyverse metapackage. (if loaded tidyverse, then do not need to load this)\n",
    "  - This package allows you to create all sorts of visualizations of data.\n",
    "- `RColorBrewer`\n",
    "  - This package provides the ability to pick custom colour schemes some of which are colourblind friendly.\n",
    "- `lubridate`\n",
    "  - part of the tidyverse metapackage. (still need to load this package **individualy**)\n",
    "  - This package is a tool to convert character strings to date vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d016d5c3-e84a-461e-95c1-ec2d19ca60b2",
   "metadata": {},
   "source": [
    "**Basic functions used to aid data visualization**\n",
    "\n",
    "- `n()`\n",
    "  - number of rows/observations in the data\n",
    "  - usually used like `group_by()` + `summarize(n = n())`to give you the count of the rows for each group\n",
    "- `slice_max(data, order_by = ..., n = ...)`\n",
    "  - `data`: what data frame we are using\n",
    "  - `order_by =`: which column we select to order, default is largest first\n",
    "  - `n`: number of rows selected\n",
    "  - This function is used to select only the top `n` data rows ordered by some column from a data frame to generate a new data frame\n",
    "  - same purpose as arrange()+slice(), but more specific and efficient\n",
    "  - `as.factor()`: simply converts an existing vector to a factor\n",
    "  - `factor(col_name, levels = c(...,...,...))`: To encode a vector as a factor; allows you to specify the values, and whether they are ordered or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aade2fa6-2753-49ca-9ad5-7802396fea2a",
   "metadata": {},
   "source": [
    "**LO1: Describe when to use what kinds of visualizations to answer specific questions using a data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d9be3-2716-4c45-a901-f28d406d2acc",
   "metadata": {},
   "source": [
    "Great visualizations clearly answers your question without distraction or additional explanantion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b306b-b90d-4fac-b868-67b51763d336",
   "metadata": {},
   "source": [
    "**4 Kinds of visualization**:\n",
    "1. **scatter plots**: visualizae the relationship between **two quantitative variables**\n",
    "2. **line plots**: visualize **trends** with respect to an **independent ordered** quantity (e.g., time)\n",
    "3. **bar plots**: visualize **comparisons of amounts**\n",
    "4. **histograms**: visualize the distribution of **one quantitative variable** (e.g, all its possible values and how often they occur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab775f28-7511-4d67-9865-cf97f5d7177f",
   "metadata": {},
   "source": [
    "**Avoid**\n",
    "- avoid using **pie charts**, better to use bars, as its easier to compare bar heights than pie slice sizes. \n",
    "- avoid using **3D visualizations**, as they are hard to understand when converted to 2D image format\n",
    "- do not use **tables** to make **numerical comparisons**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dca0ba-0624-4f1e-b9de-8b01d92306a6",
   "metadata": {},
   "source": [
    "**LO2: Given a data set and a question, select from the above plot types and use R to create a visualization that best answers the question**\n",
    "\n",
    "- bar plots ex: Compare the amount of poop different dog breeds have in 2020.\n",
    "- scatter plots ex: Visualize the relationship between BMI and health insurance cost.\n",
    "- line plots ex: visualize the trend of CO2 emmision from 2010 to 2020.\n",
    "- histograms ex: visualize the midterm grade distribution in class of 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8542100-0433-427f-a739-9b646d2fbadf",
   "metadata": {},
   "source": [
    "**LO3: Effecitve visualizations and rule of thumbs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aecc627-d88f-4f37-9927-7576dde06580",
   "metadata": {},
   "source": [
    "**Convey the message, minimize the noise!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056eeee2-e9b2-490e-b221-8a8517b1e76f",
   "metadata": {},
   "source": [
    "**1. Convey the message**\n",
    "\n",
    "- Make sure the visualization answers the question most simply and plainly as possible.\n",
    "- Use **legends**, **labels** so that your visualization is understandable without reading explanations.\n",
    "- Make sure the **text, symbols, lines...** are big enough to be easily read.\n",
    "- Make sure the data are **clearly visible**\n",
    "- Make sure to **use color schemes** that are **colorblind friendly**\n",
    "- Redundancy can be **helpful**, sometimes conveying the same message in multiple ways reinforces it for the audience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920aabe5-c831-4749-9a5c-855ce51fc86b",
   "metadata": {},
   "source": [
    "**2. Minimize noise**\n",
    "\n",
    "- Too many **different colours** can be distracting, create false patterns\n",
    "- **Overplotting** is when marks that present the data **overlap**, prevents you from seeing how many data points are represented in areas of the visualization.\n",
    "- Make plots in the **appropriate size**\n",
    "- **Don't** adjust the axes to zoom in small differences, if the difference is small, show that its small!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0335a-4d6a-4fe0-8265-d19db203c26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4260183-0325-418f-9972-c180d952c7d6",
   "metadata": {},
   "source": [
    "**General tools used to refine the 4 visualizations**\n",
    "\n",
    "Geometric Objects: specifies how the mapped data should be displayed `geom_*`\n",
    "\n",
    "- `geom_point()` for scatterplot, `geom_line()` for line plot, `geom_histogram()` for histogram, `geom_bar()` for bar plots\n",
    "- `geom_vline(x-intercept)` to add a vertical line to the plot at specified x-intercept\n",
    "  - `geom_vline(xintercept =..., linetype = \"dashed\", size = 1)`\n",
    "- `geom_hline(y-intercept)` add horizontal line at specified y-intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1981bf60-5158-42e3-98e9-2796fb3b79d1",
   "metadata": {},
   "source": [
    "Scales: Used to modify axis, legends. Adjusts how asthetic mappings are displayed\n",
    "- `scale_x_continuous()` :customize the appearance of continuous variables on the x-axis, allows you to adjust axis labels, breaks, limits, transformations\n",
    "- `scale_y_continuous()` :customize the appearance of continuous variables on the y-axis, allows you to adjust axis labels, breaks, limits, transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4aeea-88e0-4eb6-ac85-20b6fed7f11c",
   "metadata": {},
   "source": [
    "Asthetic Mappings: tells `ggplot` how the variables in the data frame map to properties of visualization (colour, shape, position, size)\n",
    "- `x`,`y`\n",
    "- `fill`:\n",
    "- `colour`:\n",
    "- `shape`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b389165c-de1d-4975-8e2c-6e4796b1f249",
   "metadata": {},
   "source": [
    "Labelling:\n",
    "\n",
    "- `xlab()`: add labels to the x axis \" \" usually include units and make label name less technical\n",
    "- `ylab()`: add lables to the y axis \" \"\n",
    "- `labs()`: general function for all labels (x, y, legend, colour...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf1c83-1302-43ab-be05-06fcf467db25",
   "metadata": {},
   "source": [
    "Font control and legend positioning:\n",
    "\n",
    "- `theme()`: changes the font size in plots\n",
    "\n",
    "`theme(text = element_text(size = 12))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89376c14-f199-47ca-85c3-375432b60eb7",
   "metadata": {},
   "source": [
    "Flipping axes:\n",
    "\n",
    "- `coord_flip()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0378a7-9df8-40ad-a439-55cb7b34001d",
   "metadata": {},
   "source": [
    "Subplots:\n",
    "\n",
    "- `facet_grid()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f227430-c14c-4a39-b13a-9904e26692d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9091828-5d0d-49c8-b9bf-934625e6f08a",
   "metadata": {},
   "source": [
    "**`ggplot()` Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e99781-cd59-4813-a207-1f076805da06",
   "metadata": {},
   "source": [
    "- `ggplot(data,aes(x= , y= , ...)) + geom_...() + ...`\n",
    "  - ggplot takes two arguments.\n",
    "  - 1st argument is the dataframe to visualize\n",
    "  - 2nd argument requires an aesthetic mapping that you would address the properties of the visualizaion with.\n",
    "  - After the ggplot function, different layers are **added** to the plot using `+` instead of `|>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f46e9-53ac-4133-b3d8-1ca04c210f59",
   "metadata": {},
   "source": [
    "- `aes()`\n",
    "  - `x =`: assign variable to x-axis\n",
    "  - `y=`: assign variable to y-axis\n",
    "  - `colour =`: assign different colors by factors of the **categorical variable** (non-numerical, factor) you input in this argument\n",
    "\n",
    "ex: in `aes(..., colour = Column (that has categories, factor))`\n",
    "\n",
    "   - `shape =`: assign different shapes by factors of the **categorical variable** you input in this argument\n",
    "   - `fill =` :(for geom_histogram and geom_bar) what factor is used to color the bars\n",
    "   - `fct_reorder()`: often used with `aes()` to reorder values\n",
    "     - The first argument defines the column to be reordered\n",
    "     - The second argument is the criteria used for reordering\n",
    "     - `fct_reorder() uses **ascending** order by default, can change into descending by `.desc=TRUE`\n",
    "     - EX: `aes(..., y=fct_reorder(column, criteria, .desc=TRUE),...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a2e013-7051-4a67-86ff-1a614edfea31",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "- `fill` and `colour` can also be used outside the `aes()` function. This is done when you want to manually assign a colour to your points/bars.\n",
    "- Anything you define in the `aes()` function MUST be labelled in the `labs()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4984c4-c263-4342-9c28-b2972f3f6759",
   "metadata": {},
   "source": [
    "- `geom_...()`\n",
    "  - `geom_bar(stat = \"identity\")`: tells ggplot2 that you will provide the y-values for the barplot, rather than counting the aggregate number of rows for each x value. (which is the default `stat = \"count\"`\n",
    "  - `geom_histogram(position = \"identity\")`: To ensure the histograms for each factor will be overlaid side-by-side, instead of stacked bars (which is default for bar plots or histograms when they are coloured by another categorical variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf4049-0055-4868-a9a7-5e60019974e1",
   "metadata": {},
   "source": [
    "- `...`\n",
    "  - `xlab()`: x-axis label, (can add `\\n` in the name to create line break)\n",
    "  - `ylab()`: y-axis label\n",
    "  - `xlim()`: set the scale limits for the x-axis. `xlim(c(lower boundary, upper boundary))`\n",
    "  - `ylim()`: set the scale limits for the y-axis. `ylim(lower, upper)`\n",
    "  - `theme(text=element_text(size = 20))`: changes the font size in plots. a good start is 20\n",
    "  - `theme(legend.position = \"top\", legend.direction = \"vertical\")`: move the legend to better display the plot. \n",
    "  - `scale_x_log10`: scale the x values to log scale.\n",
    "  - `scale_y_log10`: scale the y values to log scale.\n",
    "  - `scale_color_brewer(palette = \" \")`: allows you to choose the specific colour palette you want from the `RColorBrewer` package\n",
    "  - `scale_fill_manual`: manually select the colour we want to fill our bar into\n",
    "  - `coord_flip()`: swaps x and y coordinate axes, to give more space to labels on the x axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b14426-b4db-43de-94bd-27f8d4cf226c",
   "metadata": {},
   "source": [
    "**`facet_grid()`**\n",
    "\n",
    "Facets divide a plot into subplots based on the values of one or more discrete variables.\n",
    "\n",
    "- To facet into rows based on the discrete variable, use `rows = vars(colname)` argument\n",
    "- To facet into columns based on the discrete variable, use `cols = vars(colname)` argument\n",
    "- **Note**, column name must be wrapped by `vars()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b8fbe8-fc96-49e2-8d38-17e66c5c8a58",
   "metadata": {},
   "source": [
    "**Why is line plot sometimes better**:\n",
    "\n",
    "- Line plots connect the sequence of x and y coordinates of the observations with line segments, emphasizing their order, as x variable (eg time) has a natural order to it.\n",
    "- issue with scatterplot: overplotting can occur where data points overlap on top of one another, making the informaton presented unclear.\n",
    "\n",
    "**When is scatterplot better**:\n",
    "\n",
    "- scatterplot is good when neither of the two quantitative variables have natural order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b6926-1ca6-4e04-81f6-dbdd8d471b94",
   "metadata": {},
   "source": [
    "**Key characteristics of data**\n",
    "\n",
    "- **Direction**: if the y variable tends to increase when x increases, then y has a **positive** relationship with x. If y tends to **decrease** when x increases, then y has **negative** relationship with x. If y does not **meaningfully** increase or decrease as x increases, then y has **little or no** relationship with x.\n",
    "- **Strength**: if y **reliably** increase, decrease, or stays flat as x increases, then the relationship is **strong**. Otherwise the relationship is **weak**. (Strong when the points are more clustered and look more like \"line\" than a \"cloud\"\n",
    "- **Shape**: if you can draw a stright line roughly through the data points, the relationship is **linear**. Otherwise, it is **nonlinear**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba9e1b-0565-456b-a91a-6df69bc25ffe",
   "metadata": {},
   "source": [
    "**Example of visual redundancy**\n",
    "\n",
    "- Conveying the same information with **both scatter point color and shape** - can further improve the clarity of your visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5d7be-8cc9-486e-b61d-1f7c77601b50",
   "metadata": {},
   "source": [
    "**Bar plots vs Histograms**\n",
    "\n",
    "- It is better to use bar plots to compare value of an amount (size, proportion, count, percentage) across **different groups of categorical variables**\n",
    "- It is better to use histograms when displaying the **mean, or median values**, to show distribution of all individual data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633540b0-139d-4e9c-908f-5b5f597ba088",
   "metadata": {},
   "source": [
    "**Histograms** help us visualize how a particular variable is distributed in a data set by separating the data into bins, and then using vertical bars to show how many data points fell in each bin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae01cb-b41a-40a4-a632-276940da2529",
   "metadata": {},
   "source": [
    "**Saving the visualization**\n",
    "\n",
    "- Generally, images come in two flavours: **raster** and **vector** formats\n",
    "  - **Raster** images represent as 2D grid of square pixels, each with its own colour\n",
    "    - they are often compressed before storing to take up less space.\n",
    "  - **Lossy** format is if the image cannot be perfectly re-created when loading and displaying\n",
    "  - **Lossless** format allow a perfect display of the original image\n",
    "    - Common **raster image** file types:\n",
    "      - JPEG(.jpg, .jpeg): lossy, usually for photographs\n",
    "      - PNG (.png): lossless, usually for plots, line drawings\n",
    "      - BMP (.bmp): lossless, raw image data, no compression (rare)\n",
    "      - TIFF(.tif, .tiff): typically lossless, no compression used mostly in graphic arts publishing\n",
    "\n",
    "  - **Vector** images are represented as a collection of mathematical objects (lines, surfaces, shapes, curves). When the computer displays the image, it redraws all of the elements using their mathematical formulas.\n",
    "     - Common **vector image** file types:\n",
    "       - SVG (.svg): general-purpose use\n",
    "       - EPS (.eps), general-purpose use (rare)\n",
    "\n",
    "**Raster and vector images have opposing advantages and disadvantages**\n",
    "\n",
    "- Raster image takes same amount of time to load for same sizes images no matter the complexity, vector images takes different time and space to load according to how complex the image is.\n",
    "- You can zoom into/ scale up vector graphics as much as you like without the image looking bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2242a296-71b7-46ea-9ace-d846aaf4fd58",
   "metadata": {},
   "source": [
    "**To save the graph**:\n",
    "\n",
    "- `ggsave(file name, plot name)`: file name could end with .png, .jpg, .bmp, .tiff, .svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489b8b1-c48f-4ec8-afd2-d237264541bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b55c7b7-0081-4f0f-99a9-db20d983580e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b061d9d7-97e5-4ba7-8b7b-119ca9028fe5",
   "metadata": {},
   "source": [
    "**Chapter 12 Collaboration with version control**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b174e4df-a1d0-4337-a43d-07982b401174",
   "metadata": {},
   "source": [
    "**LO1: Describe what version control is and why data analysis projects can benefit from it**\n",
    "\n",
    "- **Version Control**: the process of **keeping a record** of **changes** to documents. (**when** changes were made) (**who** made them) throughout the history of development.\n",
    "    \n",
    "**Advantages of version control**\n",
    "1. version control tracks changes to the files in the analysis over the lifespan of the project, include when changes were made and by who. Provides ability to view ealier versions of the project and revert changes.\n",
    "2. Being able to record and view the history of a data analysis project is **important** for understandng how and why descisions were made to use one method.\n",
    "3. Helps with collaboration by sharing edits with others and resolving conflict edits.\n",
    "4. Version control tools usually include a remote repository hosting service (GitHub) that can act as a backup of the local files on computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba71b52-c023-484c-ad79-90c5abf663aa",
   "metadata": {},
   "source": [
    "**TWO things to version control a project**\n",
    "1. **version control system**: the software responsible for tracking changes, sharing changes with others, obtaining changes by others, and resolving conflicting edits. `Git`\n",
    "2. **repository hosting service**: storing a copy of the version-controlled project online, team members can access it remotely, discuss issues and bugs, and distribute final product. `GitHub`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182fdc6c-8674-4c33-8a79-de8f2aca23b0",
   "metadata": {},
   "source": [
    "**LO2: Create a remote version control repository on GitHub**\n",
    "\n",
    "**Typically, when we put a project under version control, we create **two** copies of the repository.**\n",
    "1. **local repository**: Primary workspace to create, edit, and delete files. (commonly exist on computer, and also on server **JupyterHub**.\n",
    "2. **remote repository**: Typically stored in a repository hosting service (**GitHub**), where we can easily share it with our collaborators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fffe469-6621-4788-b777-f2b125934759",
   "metadata": {},
   "source": [
    "- Both copies of repository have a **working directory**: where you can create, store, edit, and delete files.\n",
    "- Both maintain full project **history**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66f8b3-cb13-4e60-ad7b-7c55637a432b",
   "metadata": {},
   "source": [
    "**LO3: Use Jupyter's Git version control tools for project versioning and collaboration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ba076-dbab-4dff-ac9a-e7d893aba999",
   "metadata": {},
   "source": [
    "**Cloning a repository**\n",
    "\n",
    "- **Copying/downloading the entire contents** (files, project history, location of remote repository) of a remote GitHub repository **to a computer** (your local workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec3f1c-31e9-4871-af1d-e02149c25d72",
   "metadata": {},
   "source": [
    "**Git has a distinct step of ADDING files to the STAGING AREA because**:\n",
    "\n",
    "- Not all changes we make are ones we want to push to our remote GitHub repository.\n",
    "- It allows us to edit multiple files at once, but associated particular commit messages with particular files (so the commit messages can more specifically reflect the changes that were made)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d105f1e-99ad-43a6-ad07-dbbb53ac7222",
   "metadata": {},
   "source": [
    "**Commits**\n",
    "\n",
    "They are snapshot of the file contents as well as the metadata about the repository (who made the commit, when was it made)\n",
    "\n",
    "- each commit has a human-readable **message**: description of what works was done since the last commit. So that you can easily and effectively review the project's history!\n",
    "- When we commit our changes to Git, the snapshot of changes, commit message, and time, user are all saved to the Git history on LOCAL computer (local repository).\n",
    "\n",
    "To commit, we add the files to the **staging area**: not a physical location on the comupter (**conceptual placeholder** for the files until they are **committed**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d3321-ce1b-47e1-a0ef-11e2ddb9e532",
   "metadata": {},
   "source": [
    "**Pushing**\n",
    "\n",
    "Push the commits on local repository to remote repository **GitHUB**, to match what you have on local repository. (collaborators will be able to see the changes on remote repository\n",
    "\n",
    "- Pushing with Git is the act of sending changes that were committed to Git to a remote repository, for example, on GitHub.com.\n",
    "- You should push your work to GitHub anytime you want to share your work with others, or when you are done a wrk session and want to back up your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b4f957-02c6-4566-a4b0-8fee3ba23454",
   "metadata": {},
   "source": [
    "**Pulling**\n",
    "\n",
    "To obtain new changes made by others from the remote repository, synchroize your local repository to what is on the remote repository.\n",
    "\n",
    "- **Until you pull** the changes from remote repository, you will **not be able to push** any more changes yourself!\n",
    "- act of collecting changes that exists in a remote repository, that do not yet exist on the local computer you are working on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e78d857-c76d-490d-8851-bd1303c39411",
   "metadata": {},
   "source": [
    "**Version control workflows**\n",
    "\n",
    "Generally **three additional stpes** as part of regular (edit, create, delete) workflow\n",
    "1. Tell `Git` to make a **commit** of your own changes in **local repository**\n",
    "2. Tell `Git` **when** to send your **new commits** to the **remote `GitHub` repository**\n",
    "3. Tell `Git` **when** to **retrieve** any new changes made **by others** from the remote repository `GitHub`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c5cdca-d490-4b88-b61a-02507a9e496d",
   "metadata": {},
   "source": [
    "**Example Workflow on JupyterHub**\n",
    "1. Edit, create, and delete files in your cloned local repository on JupyterHub\n",
    "2. Once you want to record your current version, specify which files to \"add\" to Git's staging area. (modified files that you want a snapshot)\n",
    "3. Commit those flagged files to your repository, and include a helpful commit message to tell your collabrators what changes you have made. GitHub has not changed.\n",
    "4. Continue working\n",
    "5. When you want to store your commits from your local repository onto your cloud to share with your collaborators, you can push them back to the hosted repository on GitHub. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965912af-53fb-4f71-862f-2de31743fbe6",
   "metadata": {},
   "source": [
    "**Resolve merge conflicts**\n",
    "\n",
    "Merge conflicts: occurs when you forgot to pull before you made new changes to the file, and when the other collaborator and you worked on the same ine of code and Git will not be able to automatically merge the changes.\n",
    "\n",
    "- To fix merge conflicts: open the file in plain text editor\n",
    "- Begining of merge conflicts is preceded by `<<<<<<< HEAD` end of merge conflict is marked by `>>>>>>>`. version of change before the separator `=======` is your change and after is the other's.\n",
    "- Use plain text editor to remove the special markings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d760a20-51a8-413c-a86e-d65d836ce309",
   "metadata": {},
   "source": [
    "**Communicating using GitHub issues**\n",
    "\n",
    "- Emails and messaging apps are not designed for project specific communication.\n",
    "\n",
    "**GitHub issues**: an alternative written communication platform to email and messaging apps\n",
    "\n",
    "- Issues are opened from the \"issues\" tab on the project's GitHub page, and they remain there even after the conversation is over and issue is closed.\n",
    "- One issue thread is usually created per topic, and they are easily searchable using GitHub's search tools.\n",
    "- All issues are accessible to all project collaborators, so no one is left out of the conversaion.\n",
    "- Issues can be setup so that team members get email notifications when a new issue is created or post under issue thread. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c982f-16ed-4078-982e-a256b70ded9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60623ea-da1b-4a7e-b8b0-884d407c8bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85c7823-8622-463c-9a4a-92b34e768387",
   "metadata": {},
   "source": [
    "**Chapter 5 ClassificationI: training and predicting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d2213-4dde-46ae-940c-4df0aaed42a7",
   "metadata": {},
   "source": [
    "***Important packages for chapter 6***\n",
    "\n",
    "- `forcats`\n",
    "  - forcats package enables us to easily manipulate factors in R.\n",
    "  - factors are a special categorical type of variable in R that are often used for class/label data\n",
    "- `tidymodels`\n",
    "  - K-nearest neighbour algorithm is implemented in the parsnip PACKAGE included in the tidymodels package collection\n",
    "  - The tidymodels package collection also provides the workflow\n",
    "- `parsnip`\n",
    "  - Part of the `tidyverse` metapackage\n",
    "  - The K-neaest neighbour algorithm is implemented in the \"parsnip\" package included in tidymodels package collection with many other models.\n",
    "  - the tidymodels collection provides tools to help make and use models, such as classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a485c-7e30-45ce-b0b3-d1e605745403",
   "metadata": {},
   "source": [
    "**LO1: Recognize situations where a classifier would be appropriate for making predictions**\n",
    "\n",
    "**Classification**: predicting a **categorical class (label)** for an observation given its other variables(features).\n",
    "\n",
    "- Generally, a classifier assigns an observation without a known class, to a class based on how similar it is to other observations with known class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1654eb6-941f-4255-adc9-d266e812af3f",
   "metadata": {},
   "source": [
    "**K-nearest neighbors**: (a classifier, an algorithm), one method used to predict a categorical class/label for an observation.\n",
    "\n",
    "- *binary classification*: basic classification problem where only *two* categorical class/labels are involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064261f4-5c7a-484c-beac-2c17f4d1d82f",
   "metadata": {},
   "source": [
    "**LO2: Describe what a training data set is and how it is used in classification.**\n",
    "\n",
    "- **Training set**: A collection of observations with known classes/labels that can be used to train, teach the classifier which can then predict the new observation's class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff3b27-43a5-4652-b2d0-b97e412f3a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a666910e-6243-4909-a023-ff3ff69de40e",
   "metadata": {},
   "source": [
    "***Common functions to use in this chapter***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9705cf-c338-4213-864c-dd98de449923",
   "metadata": {},
   "source": [
    "- `glimpse(df)`\n",
    "  - This function can make it easier to inspect the data when we have a lot of columns\n",
    "- `factor(col_name, levels = c(..., ..., ...))`\n",
    "  - Used to encode a vector as a factor; allows you to specify the values, and whether they are ordered or not\n",
    "  - first argument is the column you want to convert\n",
    "  - second argument are the values/categories/levels that are ordered.\n",
    "- `add_row(df, col_name_1 = ..., col_name_2 = ..., ..., col_name_n = ...)`\n",
    "  - creates and adds a row/observation to the df\n",
    "  - specify the name and respective values of each column of the df in argument\n",
    "- `as_factor()`\n",
    "  - converts the column/variable into a statistical categorical variable\n",
    "  - `mutate(df, new_name = as_factor(chosen column))`\n",
    "- `levels()`\n",
    "  - Factors have what are called \"levels\", which you can think of as categories\n",
    "  - This function return the name of each category in that column\n",
    "  - levels() function requires a vector as its argument\n",
    "- `dist()`\n",
    "  - finds the euclidean distance between the specified observations of the dataframe.\n",
    "  - this is used with the `slice()` function to first obstain the rows and then the result is piped into `dist()`\n",
    "  - if there are more than 2 rows, the result is a matric showing the distance between each row\n",
    "- `distinct`\n",
    "  - can be used to see all the unique class values present in that column\n",
    "- `fct_recode`\n",
    "  - Used to replace the names of factor values with other names. `\"new name\" = \"old name\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ade0c-7f85-4103-8878-710cd0b860b5",
   "metadata": {},
   "source": [
    "**LO3: Compute, by hand, the straight-line (Euclidean) distance between points on a graph when there are two predictor variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe2c9e-a78e-43ff-a818-af87e1f185fc",
   "metadata": {},
   "source": [
    "1. Distance bewteen points:\n",
    "\n",
    "   - Formula: `Distance = sqrt((ax-bx)^2)+((ay-by)^2)+((az-bz)^2)+...)`\n",
    "   - use `mutate` to calculate the distance from new observation:\n",
    "- For example, manually find K=5:\n",
    "   - `mutate(dist_from_new = sqrt((column1 - new_obs_colum1)^2 + (column2 - new_obs_column2)^2)`\n",
    "   - `slice_min(dist_from_new, n = 5)`, which takes the 5 rows of minimum distance\n",
    "   - And then classify the new obs based on majority voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583278a-d07f-4aa9-ace8-5524fffd7275",
   "metadata": {},
   "source": [
    "**Summary of K-nearest neighbors algorithm**\n",
    "1. Compute the distance between the new observation and each observation in the training set. `mutate()`\n",
    "2. Sort the data table in ascending order to the distances `slice_min()`\n",
    "3. Choose the top K rows of the sorted table\n",
    "4. Classify the new observation based on majority vote of the neighbor classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25916afa-825c-4641-b0bc-57179f906ce3",
   "metadata": {},
   "source": [
    "**LO4: Explain the K-nearest neighbors classification algorithm**\n",
    "\n",
    "- K-nearest neighbor algorithm is a method of classification that classifies new observations based on its **similarities** to **nearby points**\n",
    "- KNN works in the following order:\n",
    "  1. choose K: the number of neighbors\n",
    "  2. calculate the distance of each neighbor to the new obs using euclidean methods\n",
    "  3. find the K nearest neighbors\n",
    "  4. assign the class to the new observation by the majority vote among K nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341790f-7c15-49cb-b273-6baf6c7ca0d0",
   "metadata": {},
   "source": [
    "**LO5: Perform K-nearest neighbors classification in R using `tidymodels`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9235779-c52a-4a42-a53f-7dd37296e71d",
   "metadata": {},
   "source": [
    "1. Create a *model specification* for KNN.\n",
    "\n",
    "   `knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 5) |>\n",
    "   set_engine(\"kknn\") |>\n",
    "   set_mode(\"classification\")`\n",
    "\n",
    "- First, use the nearest_neighbor function\n",
    "- `weight_func` argument controls how neighbors vote, `\"rectangular` allows each K nearest neighbors to get exactly 1 vote.\n",
    "- set K=5 using `neighbors` argument\n",
    "- Second, use `set_engine()` specify the package or system will be used for *training the model* in here, use `\"kknn\"` engine.\n",
    "- Last, specify that this is a classification problem with `set_mode()` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4060cabc-3bff-4ddc-8bf8-15d70af2150c",
   "metadata": {},
   "source": [
    "2. *fit* the model on the data frame\n",
    "\n",
    "   `fit(knn_spec, response_variable ~ predictor_variable1 + predictor_variable2, data = data frame)`\n",
    "\n",
    "   - First, the specified model `knn_spec` to be fitted\n",
    "   - Specify the variables to use to make the prediction `predictor`, and the response variable before it.\n",
    "   - lastly, don't forget the dataframe to fit the model to `data =`\n",
    "- *Note*: you can use argument `response_variable ~ .` to use all the other variables in this data as predictors.\n",
    "- *Note*: The fit object lists the functions that trains the model as well as the \"best\" settings for the number of neighbours and weight function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e40ee-b20e-4d41-b8be-02b2a9b5e23c",
   "metadata": {},
   "source": [
    "*Side Note*: `new_obs <- tibble(x column = ..., y column = ..., zcolumn = ..., .....)` creates a new observation with the x and y values. Can have more values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e5e8f-6715-48ac-bd6e-a77b8f20fbbc",
   "metadata": {},
   "source": [
    "3. make the *prediction* on the new observation\n",
    "\n",
    "   `predict(knn_fit, new_obs)`\n",
    "\n",
    "   - prediction is made on the new observation using the fitted model and the new observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ddfb42-cf37-42eb-8bc0-53f908085c2f",
   "metadata": {},
   "source": [
    "**LO6: Use a `recipe` to center, scale, balance, and impute data as a preprocession step**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f80aaa-522c-44ca-8faa-5987fc60ba28",
   "metadata": {},
   "source": [
    "1. *Center and scaling*\n",
    "\n",
    "   - Because KNN predicts the classes by identifying the nearest observations using euclidean straight line calculations, **any variables with a large scale will have a much larger effect than variables with a small sclae**\n",
    "   - Just because a variable is large doesn't mean its more important.\n",
    "   - In many other predictive models: *center* of each variable matters as well.\n",
    "\n",
    "***Standadrize*** data:\n",
    "1. Subtract each value by the mean *(center the variable)* All variables will have a mean of **0**\n",
    "2. Divide each by the standard deviation *(scale the variable)* All variables will have a standard deviation of **1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fb116c-bea6-4a0d-a255-76d64c9a73fe",
   "metadata": {},
   "source": [
    "**Common problems using K-NN classification**\n",
    "1. **Varying scales of each variable**\n",
    "   when using a KNN, the scale of each variable matters since large scale variables can have a greater(unwanted) affects.\n",
    "2. **Class imbalance**\n",
    "   another potential issue in a classifier is class imbalance, *when one lbel is much more common than another*\n",
    "\n",
    "   if there are many more data points with one label overall, the algorithm is more likely to pick that label in general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2df37f-8b70-4edf-9617-5074f88fbcc9",
   "metadata": {},
   "source": [
    "***The recipe***:\n",
    "\n",
    "`recipe <- recipe(response ~ predictors, data = dataframe) |>`\n",
    "\n",
    "          `step_scale(all_predictors()) |>`\n",
    "\n",
    "          `step_center(all_predictors()) |>`\n",
    "\n",
    "          `prep()`\n",
    "\n",
    "`scaled_df <- bake(recipe, df)`\n",
    "\n",
    "- `recipe()` creates a recipe for Preprocessing Data.\n",
    "- `prep()` function finalizes the recipe by using the data to compute anything necessary to run the recipe (in this case, the column means and standard deviations).\n",
    "- `bake()` applies the results of `prep()` onto the data.\n",
    "- **prep() and bake() are separate because if additional data set is to be calculated using the prepped data set, then further calculations can be done before `bake()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f75d49-d3d9-4bf3-a842-5bdd1e66c0c6",
   "metadata": {},
   "source": [
    "**Proper use of recipe helps keep our code simple, readable, and error-free**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa257b-22f1-4d2f-a9c4-d648135690d8",
   "metadata": {},
   "source": [
    "** There are tools provided by `tidymodels` to automatically apply `prep` and `bake`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c422dd3-f78e-497f-a61f-6855b6f481e4",
   "metadata": {},
   "source": [
    "**Why we need to standardize data**:\n",
    "\n",
    "- For unscaled data, the variable that has a larger scale will dominate in the distance calculation, making the smaller scaled varaible's impact negligible. This causes inaccurate and biased nearest neighbors to be selected, leading to unreliable classification. Standardization make sure all variables can equally contributing to the nearest neighbors selection, improving the reliability of the prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d145d13-537a-487d-b99d-e705ab22db44",
   "metadata": {},
   "source": [
    "**Balancing**\n",
    "\n",
    "Issue:*imbalance*: when one label is much more common than another. Since K uses labels of nearby points to predict the new point, if one label is much more frequent than another, the algorithm is more likely to pick that label in general.\n",
    "\n",
    "- Rebalance the data by oversampling the rare class.\n",
    "- Basically replicate the rare observations multiple times in our data \n",
    "- Use `step_upsample(responder, over_ratio = 1, skip = FALSE)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf881a13-2e0d-4300-aa77-643cb8a9c8db",
   "metadata": {},
   "source": [
    "**Missing data**\n",
    "\n",
    "Issue: observations where the values of some of the variables were not recorded.\n",
    "\n",
    "- KNN requires access to *all* values for *all* observations in the training set to calculate straight-line distance to nearby training observations.\n",
    "\n",
    "1. If *not too many missing values*: simply remove the observations : `drop_na()`\n",
    "2. If *many of the rows have missing entries*: **impute** the missing entries with the *mean*. Use `step_impute_mean(all_predictors())` in the recipe to fill in the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f4ab1-5df6-479c-a9d7-f9fd03dc35d3",
   "metadata": {},
   "source": [
    "**LO7: Combine preprocessing and model training using a `workflow`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cec444-ef58-4096-b648-2e9952392f92",
   "metadata": {},
   "source": [
    "`workflow`: a way to chain together multiple data analysis steps without a lot of code for intermediate steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b0439c-77d7-474c-992b-5cf832aa67a1",
   "metadata": {},
   "source": [
    "`prep()` function is unecessary when the preprocessing is placed in a workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189914c9-8c7e-4831-910d-4fcf619ac34f",
   "metadata": {},
   "source": [
    "`knn_fit <- workflow() |>`\n",
    "\n",
    "    `add_recipe(recipe_name) |>`\n",
    "    \n",
    "    `add_model(knn_spec) |>`\n",
    "    \n",
    "    `fit(data = dataframe)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c531e1-1573-4e20-be8b-34f37b653332",
   "metadata": {},
   "source": [
    "*`fit()`* is used to fit the whole workflow on the data.\n",
    "\n",
    "**formula is not needed for `fit()` as it is included in the recipe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e415fa-15f5-490f-a834-defe10a1a6be",
   "metadata": {},
   "source": [
    "- Now the fit object lists the function that trains the model as well as the \"best\" settings for the number of neighbors and weight function.\n",
    "- *the fit object* *also* includes information about the **overall workflow**: including the centering and scaling preprocessing steps.\n",
    "- **NOW** when we apply the `predict` function on the new observation, it will apply the same recipe steps to the new observation . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e33ca-a58d-4af2-858a-109dabb83e6a",
   "metadata": {},
   "source": [
    "***set.seed()***: used to ensure every operation involing random numbers will produce reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c1c69-9ee3-4c16-9482-6d06110b8b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bbe4802-845b-42ef-b999-7cf7d3f7b8ea",
   "metadata": {},
   "source": [
    "#### Little additions the day before the midterm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b14ad-7561-495b-844e-7754ba713714",
   "metadata": {},
   "source": [
    "- databases do things in the *laziest* way possible, this is so that it can help make things a lot faster with large datasets.\n",
    "- facet_wrap() is used to create many plots side by side and wrapped around a new line if too many plots are created.\n",
    "- `!is.na(col)` can be used to filter for values in the column that is NOT equal (`!=`) to NA\n",
    "- `options(repr.plot.width = 10, repr.plot.height = 20)` is used to adjust plot size by length and width on the screen.\n",
    "- `show_query(tbl(dataset,\"table\"))` is used to look at the SQL commands sent to the database from the tbl commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac11ab-2e8c-4e2f-b88f-fe03db963db7",
   "metadata": {},
   "source": [
    "**Chapter 6: Evaluation and Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032cdc1a-133f-4f2c-b568-b757e4264310",
   "metadata": {},
   "source": [
    "**Common functions we may use**\n",
    "\n",
    "- `bind_cols(col_object,df)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef91286-2738-46d9-84e6-94af4212dc36",
   "metadata": {},
   "source": [
    "**LO 1: Describe what training, validation and test data sets are and how they are used in classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b0349f-fdca-4b57-8684-5be48f4a16c1",
   "metadata": {},
   "source": [
    "How to measure how \"good\" our classifier is?\n",
    "\n",
    "- Our classifier is good if it provides accurate predictions on data NOT seen during training: this shows that it has actually learned about **the relationship** between the predictor variables instead of simply memorizing the labels of individual training data examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5c94c-8617-49ed-bbd7-763d5920735e",
   "metadata": {},
   "source": [
    "To evaluate the classifier without needing great amount of data from the actual source:\n",
    "\n",
    "- we can SPLIT the data into two sets: Training & Test set.\n",
    "1. First ONLY use **training set** to build our classifier, store the test set untouched\n",
    "2. Then use classifier to predict the labels in the test set. So we can compare it with the actual labels to conclude our confidence level that the classifier will accurately predict labels for **BRAND NEW** observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20394195-6cfd-45de-bf4d-e3fa5f60261b",
   "metadata": {},
   "source": [
    "**Code to split the data in training, validation and test sets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09bb075-1efb-40b0-83ab-ee0e1b217f42",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3b5e8da-5f05-4c8d-996a-771c8d1b72c3",
   "metadata": {},
   "source": [
    "**LO 2: Describe and interpret accuracy, precision, and recall in R using test set, single validation set, and cross-validation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a8f7a-eee3-459e-aaad-2725068e64c2",
   "metadata": {},
   "source": [
    "**Ways to assess how well the predictions match the actual:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666198ac-7077-414a-b54e-2a0db6e279d6",
   "metadata": {},
   "source": [
    "1. `prediction accuracy`: (# correct predictions)/(total predictions)\n",
    "\n",
    "   - Benefits: Convenient, general-purpose way to summarize the performance of a classifier with a single number.\n",
    "   - Downside: ONLY tells us how OFTEN the classifier makes mistakes in GENERAL, **NOT what KINDS of mistake**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa3e25-b201-4318-af99-053cb7c1eea3",
   "metadata": {},
   "source": [
    "2. `confusion matrix`: Shows how many test set labels of **each type** are predicted correctly and incorrectly.\n",
    "\n",
    "   - Benefits: Gives more detail about the kinds of mistakes the classfier tends to make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf85e0e-1132-4370-abbf-f753d7e84fb9",
   "metadata": {},
   "source": [
    "**4 kinds of predictions the classifier can make:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb132e55-b48f-4ad7-9014-b73b6a4ed9a5",
   "metadata": {},
   "source": [
    "- We typically refer to the label we are more interested in as *positive*\n",
    "1. **True Positive**: *positive* label classified as *positive*\n",
    "2. **False Positive**: *negative* label classfied as *positive*\n",
    "3. **True Negative**: *negative* label classified as *negative*\n",
    "4. **False Negative**: *positive* label classfied as *negative*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3e3ce-92fd-4e67-8c5d-e1332ce0a5b7",
   "metadata": {},
   "source": [
    "3. `Precision`: quantifies how many of the positive predictions were ***actually*** positive\n",
    "\n",
    "Formula: (# correct positive predictions)/(total positive predictions)\n",
    "   - High precision: a calssifier predicts something to be postive, we can TRUST that it is actually positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf04ac-33bb-44ca-818f-f0735aecd59f",
   "metadata": {},
   "source": [
    "4. `Recall`: quantifies **how many** of the positive observations in the test set **were identified** as positive.\n",
    "\n",
    "Formula: (# correct positive predictions)/(total positive test set observations)\n",
    "   - High recall: We TRUST classifier can FIND the positive labels present\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61827236-93ca-438f-8dce-bfa7a25e38fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5479f947-df1e-44df-9fa2-d08b696fd020",
   "metadata": {},
   "source": [
    "**LO 3: Set the random seed in R using the `set.seed()` function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e90bdd-10f4-4b9f-8b2e-81b040473f71",
   "metadata": {},
   "source": [
    "Purpose: We use randomness anytime we need to make a descision in our analysis that **needs to be fair, unbiased, NOT influenced by human input**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b848dd2-01fa-4ff8-9207-8ced03fd3e46",
   "metadata": {},
   "source": [
    "EX: Here for classification evaluation, we want R to *randomly* split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514051a3-dd2c-4ff7-bf0d-3f977960cdac",
   "metadata": {},
   "source": [
    "**In R, the randomness is actually NOT *random*.** \n",
    "Once we set the seed `set.seed`, everything may LOOK random, but is actually totally reproducible. ***AS LONG AS its the SAME seed value!***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c951f7-20ec-4b0f-a316-58fb033fe9e9",
   "metadata": {},
   "source": [
    "**Watch out**: \n",
    "- If you do not set seed at the begining, the results will NOT be reproducible!!\n",
    "- If you set multiple seeds, the results will NOT be as randome as it should!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c4ad8-fa7d-43b1-a5e8-eba4efc29378",
   "metadata": {},
   "source": [
    "**LO 4:Evaluating performance with `tidymodels`** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42abed81-a1b1-4e8e-9ffa-c55b2d62c53f",
   "metadata": {},
   "source": [
    "Steps to assess the classifier:\n",
    "\n",
    "**1. Create the Training set and Test Set**\n",
    "\n",
    "- Training Set should be a 50-100% split of the data (usually use 0.75)\n",
    "- Test Set should be the remaining 0-50% of the data (usually 0.25)\n",
    "  - You want to trade off between:\n",
    "    - training an accurate model (by using a **larger training** data set\n",
    "    - getting an accurate evaluation of its performance (by using a **larger Test** data set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d890d7-09f8-4c00-b489-6ee48d9be0ee",
   "metadata": {},
   "source": [
    "- `initial_split(data, prop=..., strata= target_column)`\n",
    "  - `prop=` is the proportion you want for the training set (eg. 0.75)\n",
    "  - `strata=` stratafies the variable we want to ensure that the same proportion of different classes of that variables ends up in BOTH training and testing sets.\n",
    "  - use `set.seed()` for reproducible results as `initial_split()` randomly samples from the data.\n",
    "  - use `training(split_object)` & `testing(split_object)` to assign the training and test sets to reference objects.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407d3ff-8d5d-42ef-b2f3-052fcc127a0b",
   "metadata": {},
   "source": [
    "- can use `glimpse(testing)` to view the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822555b-f4f1-40e8-9e04-2fbb79dad759",
   "metadata": {},
   "source": [
    "**2. Pre-Process the data**\n",
    "\n",
    "- K-NN is sensitive to the scale of predictors, so we should perform some preprocessing to standardize them\n",
    "- We should create the standardization preprocessor **USING ONLY training data**. (This ensures our test data does not influence any aspects of our model training). We want our model to have never seen the test set before!\n",
    "- create the recipe, `step_scale(all_predictors())`, `step_centre(all_predictors())`\n",
    "- Once we have created the standardization preprocessor, we can then apply it **separately** to both the **training** and **test** datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d4db5b-c93a-4176-9ea9-2c9c9501654b",
   "metadata": {},
   "source": [
    "**3. Train the Classifier**\n",
    "\n",
    "- Create the K-nearest neighbor classifier with **only** the **training set**, using standard procedure, `knn_spec`, `knn_fit` workflow()...\n",
    "\n",
    "  (Here, K-nearest neighbours algorithm can randomly select the majority neighbour class if there is a tie between two classes or more. This is another reason WHY set.seed() is useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db1afd0-dc08-449e-933d-3fc74ce37614",
   "metadata": {},
   "source": [
    "**4. Create the labels in the Test set**\n",
    "\n",
    "- Predict the class labels for our **test set** using the `predict()` function\n",
    "- Use the `bind_cols(prediction data, test data)` to add the column of predictions to the original test data creating the predictions dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df205b-1e1b-45a0-9090-e1c227b18316",
   "metadata": {},
   "source": [
    "**5. Compute the accuracy**\n",
    "\n",
    "- To assess classifier's accuracy, we use the `metrics()` function.\n",
    "  - `metrics(data, truth = target_column, estimate = .pred_class)`\n",
    "  - `filter(.metric==\"accuracy\")`\n",
    "- To check the order of labels in the target variable:\n",
    "  - `pull(prediction data, target_column)` |> `levels()`\n",
    "- To find the precision:\n",
    "  - `precision(truth= target_column, estimate=.pred_class, event_level=\"positive event level(first or second)\")`\n",
    "- To find the recall:\n",
    "  - `recall(prediction data, truth=tageted column, estimate=.pred_class, event_level= \"first or second\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c7ef8e-09a8-4d2f-8026-5eb8955080cd",
   "metadata": {},
   "source": [
    "**We can also look at confusion matrix for the classifier**:\n",
    "\n",
    "- `conf_mat(prediction data, truth=target column, estimate=.pred_class)`\n",
    "- show us the table of predicted labels and correct labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a211564b-80b0-45f3-a75d-f4353819601c",
   "metadata": {},
   "source": [
    "* It is important to look at the confusion matrix to see whether the classifier is \"good\" in certain contexts, and whether we would like high precision or high recall depends on the application of this classifier.\n",
    "* Majority classifier ALWAYS guesses the majority class label from the training data, no matter the predictors. So we would like our classifier's accuracy to be higher than the majority classifier's accuracy for sure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a9dd7-6a0d-4d37-9629-8af02d6625ad",
   "metadata": {},
   "source": [
    "**LO5: Tuning the model, choose the number of neighbors in a K-nearest neighbors classifier by maximizaing the estimated cross-validation accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e5a10-a3f0-49df-8793-56bfa27ea045",
   "metadata": {},
   "source": [
    "- Predictive models such as K-NN have parameter that we have to pick: in K-NN we have to pick the number of neighbours K fro the class vote.\n",
    "- Making the most optimal selection is called **TUning** the model, part of model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafbbe1b-cfe7-46ad-a1dd-be159cd93ba7",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "How do we tune the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bf8bb6-24a2-4f6e-a928-e76f9a3f98f4",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "1. Split the **Training data** further into **two** subsets, called the **training (sub)set** and **validation set**.\n",
    "2. Use the **training (sub)set** for building the classifier, and the **validation set** for evaluating it!!\n",
    "3. Then we will try different values of the parameter K and pick the one that yields the highest accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e684e-7b68-4d0a-987f-cbfc28ef4de4",
   "metadata": {},
   "source": [
    "**Cross Validation Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71b6c3-d1fc-4d73-a246-8cd9bcf951b6",
   "metadata": {},
   "source": [
    "- Different from the `initial_split` which is just **one** split, here we are free to create multiple train/validation splits to have multiple classifiers. Then choose a parameter value based on **all** of the different results.\n",
    "- This leads to a better choice of K for the overall set of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3527ca-c3d2-43e7-956f-2d5fd5256ca1",
   "metadata": {},
   "source": [
    "* Averaging all validation set accuracies help reduce the influence of any one (un)lucky validation set on the estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae11c86-6b30-49f3-bff6-5399c4e3b2fb",
   "metadata": {},
   "source": [
    "**How Cross-validation works?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00040fd-6ede-4a01-8258-94aee2af0454",
   "metadata": {},
   "source": [
    "- Instead of randomly splitting the data, we want each observation in the data set to be used in a validation set only a single time.\n",
    "- The name for this strategy is called cross-validation.\n",
    "- In cross-validation, we split our overall **training data** into *V* evenly sized chunks/folds\n",
    "- Then iteratively use 1 chunk as the **Validation set** and combine the remaining *V-1* chunks as the **training (sub)set**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6c6da-5cec-4e99-9c44-6824cd7d5621",
   "metadata": {},
   "source": [
    "**Use the following functions to perform *V-fold* Cross Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb534eff-9085-48ce-a728-fb639953ffd8",
   "metadata": {},
   "source": [
    "- `vfold_cv(training_dataframe, v=..., strata= target_column)`\n",
    "  - This function splits our training data into V-folds automatically\n",
    "  - This is to be done after data has been split into **training** and **Testing** sets\n",
    "  - Cross-validation uses a random process to select how to partition the training data, therefore set.seed() important here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020fbce-7123-4807-881f-9bd1fad47518",
   "metadata": {},
   "source": [
    "- `fit_resamples(..., resamples= df_vfold)` instead of `fit(data)`\n",
    "  - Use instead of `fit()` function when doing cross-validation for **only specified neighbors**\n",
    "  - This runs cross-validation on each train/validation split\n",
    "  - first argument is the `workflow()` function which is piped in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27657304-61e9-49df-9524-1c687c4c24d1",
   "metadata": {},
   "source": [
    "- `tune_grid(..., resamples=df_vfold, grid=n)`\n",
    "  - It is used **instead** of `fit_resamples()` function when doing cross-validation for *n* neighbors.\n",
    "  - fits the model for each value in a range of parameter values\n",
    "  - third argument `grid` specifies that the tuning should try at most *n* values of the number of neighbors K when tuning.\n",
    "  - first argument `workflow()` is piped in.\n",
    "  - We set the seed very begining to ensure results from tuning are reproducible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc08e97-8490-4209-b70c-18b0c2e7a9b2",
   "metadata": {},
   "source": [
    "- specifying the `grid` (kvals)\n",
    "  - we use the code: `k_vals<- tibble(neighbors= seq(from = 1, to = 100, by=5))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13106c7f-40a0-414b-8231-58ebedef633a",
   "metadata": {},
   "source": [
    "- `collect_metrics(...)`\n",
    "  - used instead of `metrics()` function when doing cross-validation\n",
    "  - used to aggregate the mean and standard error of the classifier's validation accuracy across the folds\n",
    "  - argument is the `workflow` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbeb6b4-a038-4a12-9db1-2b23c9f21107",
   "metadata": {},
   "source": [
    "- `tune()`\n",
    "  - Each parameter in the model to be tuned should be specified as `tune()` in the model specification rather than given a particular value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b1866c-cebb-43a9-9587-12f62387c213",
   "metadata": {},
   "source": [
    "- to pull out the K with highest accuracy:\n",
    "  `best_k<-accuracies df|> arrange(desc(mean))|> head(1)|> pull(neighbors)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111818a4-a55a-4cfd-bece-e5ebe08f31f5",
   "metadata": {},
   "source": [
    "**Notes about V-fold cross validation**\n",
    "\n",
    "- when you do cross-validation, you need to consider the size of the data, the speed of the algorithm and computer.\n",
    "- In practice, typically V is chosen to be either **5** or **10**.\n",
    "- The more the folds, the lesser the standard error, BUT the more expensive the computation\n",
    "- How good or not the prediction accuracy is depends entirely on the downstream application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926127e0-2728-4d0b-b60e-14c76dc3ae12",
   "metadata": {},
   "source": [
    "**How do you decide which parameter value K is the Best?**\n",
    "\n",
    "1. We get roughly the **optimal accuracy**, which means that changing the value to a nearby K does not **decrease** the accuracy **too much**, making our choice reliable in the prsence of uncertainty.\n",
    "2. The cost of training the model is not prohibitice (too large of K is EXPENSIVE!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f81b46-3008-4e8e-a8c6-c9a8de1ab874",
   "metadata": {},
   "source": [
    "**LO6: Describe Underfitting and Overfitting, and relate it to the number of neighbors in K-nearest eighbors classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a1265-6a27-4747-87c3-2e16b190a7ec",
   "metadata": {},
   "source": [
    "**Under-fitting**:\n",
    "\n",
    "- Increase the K, more and more training observations get a \"say\" in what the class of a new observation is.\n",
    "- Causes an \"averaging effect\" making the boundary between where the classifier would predict type 1 and type 2 to smooth out and become simpler (too simpler).\n",
    "\n",
    "- **In general, if the model isn't influenced enough by the training data, it is said to underfit the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af55fd58-4057-49bd-9acc-5f9952291d8b",
   "metadata": {},
   "source": [
    "**Over_fitting**:\n",
    "\n",
    "- decrease the K, each individual data point has a tronger and stronger vote.\n",
    "- Causes more \"jagged\" boundary between type 1 and 2, **less simple model**, classifier become unreliable on new data.\n",
    "- If we had a different training set, the predictions would be completely different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e964c-95d1-46bf-8180-d0a8c6de11cd",
   "metadata": {},
   "source": [
    "- **In gneral, if the model is influenced TOO much by the training data, it is said to overfit the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c326d2-c8d3-4287-8c13-11b35167e365",
   "metadata": {},
   "source": [
    "**Advantages and Disadvantages of KNN Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512f556-ffa4-4a7d-9b16-923c7cc36003",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- Simple and easy to understand\n",
    "- No assumptions about what the data must look like\n",
    "- Works easily for binary (two-class) and multi-class (> 2 classes) classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b9b56a-4a76-4d40-b182-59ac15524a0f",
   "metadata": {},
   "source": [
    "**Disadvantages**\n",
    "\n",
    "- As data gets bigger, KNN gets slower and slower\n",
    "- Does not perform well with a large number of predictors\n",
    "- Does not perform well when classes are imbalanced (significantly more observations of one class than the other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b5b7e-a463-4e09-ba5f-63b27465484f",
   "metadata": {},
   "source": [
    "**Predictor selection**\n",
    "\n",
    "- **adding irrelevant predictors** to KNN hurts accuracy by ading random noise to the distance calculations\n",
    "- **Accuracy** declines as noise increases\n",
    "- **Best subset selection** tries every predictor combination for the best accuracy, BUT too **slow** for many variables\n",
    "- **Forward Selection** adds predictors one at a time, choosing the one that most improves cross-validation accuracy at each step, faster, still can overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e19e0a-d479-43fd-a4a4-0a7d41260cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f19353d4-75af-461a-93e0-c2b5ff867875",
   "metadata": {},
   "source": [
    "**Chapter 7.1: Regression (KNN regression)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb21a61-54b6-4dbc-a260-e461658ece65",
   "metadata": {},
   "source": [
    "**LO 1: Explain the KNN regression algorithm and describe how it differs from KNN classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6fc0d5-8c35-4bd2-ac06-fc72f1d358f8",
   "metadata": {},
   "source": [
    "Regression method is very similar to classification, both needs to split the data into testing and training, tune the model and use cross-validation to choose the K. \n",
    "\n",
    "**Difference is that regression method helps predict *numerical* variables based on one or more predictor variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dfee19-2239-4155-832f-5051a619787d",
   "metadata": {},
   "source": [
    "**When would regression be appropriate for making predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad4233c-660e-4f39-90c4-344951fde4a3",
   "metadata": {},
   "source": [
    "Answer: We use past informations to predict future observations that are *numerical* values instead of *categorical*. \n",
    "\n",
    "- Value we want to predict is called \"response variable\" and in regression, response variables are *numerical*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa99a99-82da-410d-9c17-4ba695e8f4d6",
   "metadata": {},
   "source": [
    "**LO 2: In a data set with two or more variables, perform KNN regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c81f9-b082-4a4f-9b0d-931fcdbfb119",
   "metadata": {},
   "source": [
    "**Question: Can we use a numerical predictor variable to predict a numerical response variable?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf0a4c-fa0d-46d3-9841-7f9dc566b0d8",
   "metadata": {},
   "source": [
    "**1. Create a scatterplot to explore the relationship between the two variables**: response variable on x-axis, predictor on y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574d4e3-203e-4eef-9cb2-d1ad68b79750",
   "metadata": {},
   "source": [
    "**2. Split the data**\n",
    "\n",
    "- Split the data into testing and training sets, and store the testing set in a \"lock box\" Only come back to it when we have chosen our final model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf758378-a8fe-48f2-819c-0fc47c774ca3",
   "metadata": {},
   "source": [
    "**3. Create a model specification for K-NN regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f74fd4-8c25-4d97-87e7-9eed33be234e",
   "metadata": {},
   "source": [
    "***Note***: We use `set_mode(\"regression\")` which tells tidymodels that we need to use different metrics (Ex: **RMSPE** instead of accuracy for tuning and evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba4e29-e555-42a5-8742-df0c1da87d6d",
   "metadata": {},
   "source": [
    "**4. Create a recipe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e569fb7-4f32-42a9-a9a7-fcf25e4043d7",
   "metadata": {},
   "source": [
    "- For preprocessing step, we may choose to centre and scale our data, however, if there is only ONE predictor variable, we may choose to not do preprocessing as it would not impact our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebbc774-9e0f-4058-aec6-f9e178e00aac",
   "metadata": {},
   "source": [
    "**5. Cross-validation to choose K**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530abe67-4494-4386-8fbb-2185b4a98b32",
   "metadata": {},
   "source": [
    "**Because this is predicting *numerical values*, we will never get our prediction to be EXACTLY the true value, so accuracy method does not apply here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2536ac-96ee-4333-a13e-b142c1186a46",
   "metadata": {},
   "source": [
    "- We will use **RMSPE** (roomt mean squared prediction error) on the training set.\n",
    "- RMSPE is the sum of the squared difference between predicted and true value and then averaged them. and THEN SQUARE ROOTED.\n",
    "  - **Large, positive** RMSPE means large mistakes\n",
    "  - **Small, positive** RMSPE means small mistake (prediction close to true)\n",
    "  - **SO, we choose the K with the smallest RMSPE from the cross-validations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d29f63-e67c-47e7-9244-700b0614bd3c",
   "metadata": {},
   "source": [
    "**Important NOTES**:\n",
    "\n",
    "- `RMSPE` is for calculating the root mean squared error on the testing /validation data. predicting on unseen data. Measures how well our model predicts data it was NOT trained with.\n",
    "  - this indicates how well our model generalizes to future data\n",
    "- `RMSE` is for predicting and evaluating prediction quality on training set. Measures how well our model predicts the data it was trained for.\n",
    "  - this indicates how well our model can fit our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c8a6cb-78de-4469-8ea4-19b0dec8a173",
   "metadata": {},
   "source": [
    "**6. Put recipe, model into a workflow()**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd729080-6ee9-49ba-84a5-95399804d0ee",
   "metadata": {},
   "source": [
    "**7. Run our cross-validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54ecdb-448c-4b88-b290-758252b8d611",
   "metadata": {},
   "source": [
    "- Here, we still `collect_metrics()`, but will `filter(.metric == \"rmse\")`\n",
    "- The `mean` column shows the average of the `RMSPE` of the estimate by cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c878d2-ab84-4978-bd90-84c0905f6edd",
   "metadata": {},
   "source": [
    "**8. Lastly, we take the `filter(mean == min(mean))` to find the best K with the *minimum* RMSPE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29017f-1ba7-446a-9c63-74db65d4d6ed",
   "metadata": {},
   "source": [
    "**9. evaluate the test set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be571600-2404-43d6-a77e-01b3570ab313",
   "metadata": {},
   "source": [
    "- asses how well our model predicts, we will asses its RMSPE on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35827a4-a121-40d6-a54d-ac887a7a5398",
   "metadata": {},
   "source": [
    "Standard procedures for evaluation:\n",
    "1. make a new model based on the best K\n",
    "2. fit the model to test data\n",
    "3. predict the test data with this model and `bind_cols`\n",
    "4. obtain the metrics `metrics(truth =, estimate =)` and `filter(.metric == \"rmse\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da7a427-89ff-4d35-b303-4f16a22ed960",
   "metadata": {},
   "source": [
    "**LO 3: Describe underfitting and overfitting, and relate it to the number of neighbors in K-NN regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068adbb-35cc-4866-9641-37b66cb889e8",
   "metadata": {},
   "source": [
    "- By setting the K **too small** or **too large**, we cause the RMSPE to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d2a86-4f57-4fa3-88c7-b2989708d6e4",
   "metadata": {},
   "source": [
    "**Overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00c50a-234d-457d-bca9-9c27f2727f7d",
   "metadata": {},
   "source": [
    "- **K too small**\n",
    "- The prediction follows the training set data **too closely**, model influenced too much by the data.\n",
    "- If we change the training set observations we would get ENTIRELY different prediction, and the model prediction from the previous training set would not correctly predict the new set well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fbc277-5e61-4784-8008-a10f72783a75",
   "metadata": {},
   "source": [
    "**Underfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a6a988-63e9-43bc-a6c5-f9de16533cfd",
   "metadata": {},
   "source": [
    "- **K too large**\n",
    "- Prediction line is very smooth, almost flat.\n",
    "- Our predicted values depend on too many neighbouring obervations\n",
    "- Similar, inaccurate predictions for different data given.\n",
    "- the predicting line does not follows the training set very closely, changing any observations in the training set would not really affect the prediction line at all.\n",
    "- **Model is too simple to capture the patterns of the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2667b8-7ebc-45d5-9d8f-3826a1af3903",
   "metadata": {},
   "source": [
    "**LO 4: Strengths and Limitations of KNN regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce32e76c-4d01-483a-abbe-3b18cf548697",
   "metadata": {},
   "source": [
    "**Strengths**: \n",
    "\n",
    "- Simple, does not require much assumptions of what the data should look like for the model to work\n",
    "- Works well with **non-linear** relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0796004-49ff-4d5e-b82a-6b794a4f0d3b",
   "metadata": {},
   "source": [
    "**Weaknesses**:\n",
    "\n",
    "- Becomes very slow as data gets larger\n",
    "- Does not perform well with **large numbers of predictors**\n",
    "- May not predict well for **data beyond** the range in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8389dc11-b8da-42be-be1d-7684c1724051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41bdf2f3-4330-4148-8605-7db83745f12e",
   "metadata": {},
   "source": [
    "**Chapter 7.2: Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad211331-6365-4c11-945f-08c260767ba5",
   "metadata": {},
   "source": [
    "**LO 1: Use R to fit simple and multivariable linear regression models on training data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3166407-546b-47f2-8ed6-9d85c83a59c9",
   "metadata": {},
   "source": [
    "**Simple linear regression**: involves only one predictor and one response variable. Predicting a numerical response variable of new data based on old data available. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a545ffe-a9cf-4c88-bc0d-61bbcb04163d",
   "metadata": {},
   "source": [
    "**Difference between linear and KNN**:\n",
    "\n",
    "- KNN makes predictions by looking at the K nearest neighbors and averaging over their values\n",
    "- Linear regression create a line of **best fit** and look up predictions from that line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb80c92-efb2-49f9-908b-fa87312aec84",
   "metadata": {},
   "source": [
    "**How linear regression works**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f13458f-602e-4771-8ba9-aae29eb1c9cc",
   "metadata": {},
   "source": [
    "- to have the best fit line, we just need to have the best fit with the knowledge of its **slope** coeficient, and **y-intercept**\n",
    "  - Then, we would be able to use that to make predictions of any variable values given."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db118927-877f-4179-8cf8-86d78ff4b37c",
   "metadata": {},
   "source": [
    "**How to choose the BEST best-fit**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be68f2-6556-43b7-b77b-8c4efa7a04fe",
   "metadata": {},
   "source": [
    "- simple linear regression chooses the line of best fit by choosing the line that *minimizes* the **average squared vertical distance** (equivalent to minimizing the **RMSE**)\n",
    " - average squared vertical distance between the best fit and all of the actual data points in the training data.\n",
    "- **Then**, the assess the **predictive accuracy** of the lm model, we use **RMSPE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c878c6-f7a9-4733-847b-2dca87f873c8",
   "metadata": {},
   "source": [
    "**Additionally, we do not standardize our predictors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da8a87-5863-448d-aa0f-cf4960e9f5ee",
   "metadata": {},
   "source": [
    "**Performing linear regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58faece8-8d19-414b-9d41-973e4ba3ad70",
   "metadata": {},
   "source": [
    "**1. Split the data into testing and training sets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdeea89-6f69-4110-bf3a-b6a61a3cd33c",
   "metadata": {},
   "source": [
    "**2. Create the model specification for linear regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc14276-03bd-41e2-ab41-4931062d319b",
   "metadata": {},
   "source": [
    "- use `linear_reg()` instead of `nearest_neighbors()`\n",
    "- `set_engine(\"lm\")`\n",
    "- `set_mode(\"regression\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919da43-ec03-4297-8e7a-c9920d418599",
   "metadata": {},
   "source": [
    "**3. create the recipe using training data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140feb7-bda2-47c0-bef5-cf187a47f7a3",
   "metadata": {},
   "source": [
    "**4. Use workflow() to fit/build the model on the training data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff75b5cc-c49a-4b7b-a192-7cd7c59f34c8",
   "metadata": {},
   "source": [
    "**5. Use the model fitted from training data to predict the test data, evaluate the accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc49250-96ba-4af4-90b0-4dbfa5afc26a",
   "metadata": {},
   "source": [
    "- after predict and bin_cols, use `metrics()`\n",
    "- Then, find the RMSPE by `filter(.metric == \"rmse\")` |> `select(.estimate)`|> `pull()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963f4ff-4acf-44aa-9ff3-eb05d4ed4614",
   "metadata": {},
   "source": [
    "**Side Note: To visualize simple linear regression model, we can plot the predicted value ontop of the actual values by making predictions on the maximum and minimum predictor values and connect them with a straigt line, superimpose it on top of the original scatterplot**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db86995-f397-4df9-868b-9fe39b21a916",
   "metadata": {},
   "source": [
    "**LO 3: Compare and contrast predictions obtained from KNN regression to those obtained using linear regression** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b149113a-0ed1-4489-87d1-0e2815abd9b2",
   "metadata": {},
   "source": [
    "**Advantages of KNN regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86cb39-fcd6-4809-b1c9-3b0ff308ead0",
   "metadata": {},
   "source": [
    "- Useful when relationship between predictor and response is **non-linear**.\n",
    "  - In this case the **linear regression** would be underfit (the predicted values would not match the actual values very well) Would have **High RMSE** (low fit), and **high RMSPE** when assesing the prediction quality on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6d4c2-8ecb-4007-9986-988f2d20b984",
   "metadata": {},
   "source": [
    "**Advantages of Linear regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c7584-a7f7-4d1d-8baa-0c3021c6f35c",
   "metadata": {},
   "source": [
    "1. KNN regression does NOT predict well **beyond the range of predictors in the training data**\n",
    "linear regression can fix this problem.\n",
    "2. KNN regression, method gets significantly slower as training data set gets bigger, linear regression would not have that problem.\n",
    "3. In linear regression, standardization does not affect the fit, but DOES affect the coefficient of equation.\n",
    "4. Easy to interpret, only needs **intercept** and **slope**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515839fe-8da5-4bcc-9386-04866354bdcc",
   "metadata": {},
   "source": [
    "**LO 4: Descibe how linear regression is affected by outliers and multicollinearity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4cd345-8c9a-49f2-a471-635a86516bef",
   "metadata": {},
   "source": [
    "**Outliers**: can distort the regression line by pulling it towards **extreme** values, leading to **poor fit** and **misleading predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf331e-bf8b-4773-929a-f595fe29bf59",
   "metadata": {},
   "source": [
    "**Multicollinearity**: causes the regression coefficients to become highly sensitive to specific values in the data, making the model's estimates unreliable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c137ef-76d7-405a-b55a-07de05a9f4d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14945a4b-2e4a-49cc-b8d8-c7d64ed720ea",
   "metadata": {},
   "source": [
    "**Chapter 8: Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f28b3-313d-4e2e-b6b5-d549343f0cb3",
   "metadata": {},
   "source": [
    "**Important packages for clustering**\n",
    "\n",
    "- `broom`\n",
    "  - provides us with `augment()` function\n",
    "  - provides us with `glance()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e269688-a9ce-4724-a889-eef5e77463c0",
   "metadata": {},
   "source": [
    "**LO 1: Describe when clustering is an appropriate technique to use, and what insight it might extrat from the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdbdb3-94a5-4d15-b61e-dfb0126af3ef",
   "metadata": {},
   "source": [
    "**Clustering** is a data analysis technique involve: **Separating** a data set into **subgroups** of related data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5840d55b-20bd-4d22-8fb5-faceb95ea905",
   "metadata": {},
   "source": [
    "**Why perform clustering?**\n",
    "- We can then use the **subgroups** to generate **new questions** about the data and follow up with predictive modeling.\n",
    "- Improve predictive analysis\n",
    "- In here **clustering is mostly for exploratory analysis, uncovering patterns in the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b47ab0-6cda-4f01-8c15-584b4093909f",
   "metadata": {},
   "source": [
    "**Clustering examples**\n",
    "1. Separate a data set of documents into subgroups that correspond to topics.\n",
    "2. Separate a data set of human genetic information into groups that correspond to ancestral subpopulations\n",
    "3. separate a data set of online customers into groups that correspond to purchasing behaviours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742945f7-b17e-401a-8db8-4c61dba46593",
   "metadata": {},
   "source": [
    "**Important**: Clustering is an ***unsupervised*** task: \n",
    "- We are trying to understand and examine the structure of data without any **response** variable labels or values to help us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae17693-2373-41de-a924-9582257576c7",
   "metadata": {},
   "source": [
    "**Because there is no response variable, it is NOT as EASY to evaluate the \"*quality*\" of a clustering**\n",
    "\n",
    "- With classification, we can use a test data set to assess prediction performance, in clustering, there is not one good choice for evaluation.\n",
    "- We will use visualization here to determine the quality of clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d70b951-79c1-4d8a-9da5-78d4784a50a3",
   "metadata": {},
   "source": [
    "**LO 2: Explain the K-means clustering algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e38a3a3-2d28-42c2-9f0e-c7b8374f9591",
   "metadata": {},
   "source": [
    "**1. load `library(tidyverse)` and `set.seed()`**\n",
    "\n",
    "- set a random seed is **important** because K-means clustering algorithm uses randomness when choosing a starting position for each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef39e46-26b3-4e1a-8e7c-3bd9abbac1f1",
   "metadata": {},
   "source": [
    "**Measuring cluster quality**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bdbe04-3a1c-4f86-a270-03ca415ff973",
   "metadata": {},
   "source": [
    "- The **K-means algorithm** is a procedure that groups data into K clusters\n",
    "- It starts with an **initial clustering** of the data, and then iteratively improves it by **making adjustments** to the **assignment** of data to clusters until it cannot improve any further.\n",
    "- In **K-means clustering**, we measure the **quality of a cluster** by its within-cluster sum of squared distances (WSSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcd4fe-bbf9-4d2f-9a69-57bc67a1a21e",
   "metadata": {},
   "source": [
    "Computing within squared sum of squared distances (WSSD): \n",
    "\n",
    "1. Find the cluster centers by computing mean of each variable over data points in the cluster. **cluster center is like the \"middle point\" of the cluster based on the average of each variable**\n",
    "\n",
    "- If you have a cluster of **4 data points** and using **2 variables**\n",
    "  - add up all the `x` variable values in the cluster and divide by 4 - gives the **average** `x`\n",
    "  - add up all the `y` values in the cluster and divide by 4 - gives the **average** `y`\n",
    "  - The cluster center will take on the **average x** and **average y**\n",
    "2. Next, add up the **squared distance** between **each point** in the cluster **and** the **cluster centre**. Using **Euclidean striaght line distance**\n",
    "  - The large the sum of squared distance, the more spread out the cluster.\n",
    "  - **BUT**, a cluster where points are **very close** to the center might still have large sum of squared distance if **There are many data points in the cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4047b652-cff9-4695-ae78-8a57aa4f4866",
   "metadata": {},
   "source": [
    "3. Then we add up the WSSD for each cluster to get the **total WSSD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bcd9c3-97c7-49c3-abef-11027f5402d5",
   "metadata": {},
   "source": [
    "**NOTE**: Since K-means uses straight line distances to measure quality of clustering, it will only work for quantitative variables in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e74665-c272-4ccc-9bf9-6fda6ecc901d",
   "metadata": {},
   "source": [
    "**LO 3: The clustering algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca751ccb-2d2b-4f6f-a59b-162a86687685",
   "metadata": {},
   "source": [
    "**1. We begin the K-means algorithm by *picking the K***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a006e04-46c3-4844-8313-9feb638eb6d6",
   "metadata": {},
   "source": [
    "- randomly assign a roughly equal number of observations to each of the K clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cee265-fa8e-48cc-90ca-4dd66a9ab2c0",
   "metadata": {},
   "source": [
    "**2. Two major steps to minimize the sum of WSSDs**\n",
    "\n",
    "1. **Center update**: Compute the center of each cluster\n",
    "2. **Label update**: Reassign each data points to the cluster with the nearest center.\n",
    "\n",
    "*These two steps are repeated until the cluster assignments no longer change*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f8f68-6cd8-4583-afad-73c33d9b53c0",
   "metadata": {},
   "source": [
    "**3. Random starts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b79cba-d125-47fd-9444-7d9a02009c2f",
   "metadata": {},
   "source": [
    "- Unlike regression and classification, **K-means** can get \"stuck\" in a bad solution\n",
    "- **We can get UNLUCKY random initialization**\n",
    "  - To solve this problem: We should randomly re-initialize the labels a few times, run K-means for each initialization, and pick the clustering that has the **lowest final total WSSD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad704c9-375f-4d05-a968-a269857dfea1",
   "metadata": {},
   "source": [
    "**4. In order to cluster data using K-means, we also have to pick the number of clusters K**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56c85d-7a51-4f15-9399-e35bead02e6f",
   "metadata": {},
   "source": [
    "- No response variable, **cannot perform cross-validation**\n",
    "- If **K too small**, then the clustering merges two or more separate groups of data - **large total WSSD**\n",
    "- If **K too big**, the clustering divides subgroups into multiple even smaller groups - Indeed **decrease total WSSD** but by **ONLY insignificant amount**\n",
    "- The best K, we want the \"elbow\" point, where the total WSSD starts to level off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f0145-cf1b-4eb9-884e-b20e7360c338",
   "metadata": {},
   "source": [
    "**Common functions used**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186f81a-8ed3-4245-ae22-1406e667109e",
   "metadata": {},
   "source": [
    "- `augment(kmeans_fit_object, original_data)`\n",
    "  - takes in the model and the original data frame, and returns a data frame with the data and the cluster assignments for each point (kind of like bind_cols)\n",
    "  - this function helps us to plot and identify different clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d01353-adde-438f-9ac9-f28edd495c40",
   "metadata": {},
   "source": [
    "- `unnest(glanced)`\n",
    "  - unpacks the data frames into simpler column data types\n",
    "  - this is used when a data frame containing clustering statistics for each k-means object is created and we want to \"unpack\" these statistics\n",
    "  - Because each value of the column/vector is a list of statistics, therefore, these lists are nested inside each element of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4384e56-a001-4daa-83d3-6ac6f303f945",
   "metadata": {},
   "source": [
    "**LO 4: Performing K-means**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396da292-775b-4e43-97b9-ee156e87994c",
   "metadata": {},
   "source": [
    "**NOTE**: K-means clustering uses straight-line distance to decide which cluster does a point belongs to, so we **must scale the variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48248411-18ff-4833-b966-960efaa87053",
   "metadata": {},
   "source": [
    "**(1). Create a recipe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309a2f3-1e36-463d-ac79-44ee6ace7e7a",
   "metadata": {},
   "source": [
    "- **make sure to scale all variables** `recipe(~., data=)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7847cb-f88f-4437-aa7a-983c3ec60992",
   "metadata": {},
   "source": [
    "**(2). Create the `k_means` model specification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7734bb-17e3-4c32-8247-1a7d7afb9bb6",
   "metadata": {},
   "source": [
    "- We will use `k_means(num_clusters = )` function for this clustering model\n",
    "- `set_engine(\"stats\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3323e434-1d61-427d-9632-8262baf52cb8",
   "metadata": {},
   "source": [
    "**(3) create the workflow()**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ee778-3fde-4a46-8fdc-c88a3be837d6",
   "metadata": {},
   "source": [
    "- combine the recipe and model specification in a workflow and use the `fit` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027b87e-b1f1-4205-b027-2b1a6ba44542",
   "metadata": {},
   "source": [
    "**NOTE**: K-means uses random initialization of the assignments, so we should have set.seed in the begining to make the clustering reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d814905b-d2d1-4843-aa6a-5c1e50183aca",
   "metadata": {},
   "source": [
    "**(4) Visualize the clusters with *coloured scatter plot***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64070ea-01ac-4b00-a0a8-55394f58f90a",
   "metadata": {},
   "source": [
    "- We need to first augment the original data frame with the cluster assignments\n",
    "- we need to `augment(kmeans_fit, original data)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fefd12c-d1d6-425e-9821-eaad2843d3cc",
   "metadata": {},
   "source": [
    "*`agument()` function is from `tidyclust`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99046acc-f5bb-4cee-b0fe-76fef4fab63d",
   "metadata": {},
   "source": [
    "- After we have our augmented data frame, we can plot the *unstandardized* data, and colour the clusters\n",
    "- `colour = .pred_cluster`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9840e8e-9957-4251-9741-30fb82c7e588",
   "metadata": {},
   "source": [
    "**(5) Select the best K (finding the \"elbow point\")**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd74e9-b55d-4f4e-974c-b7c1b59e0146",
   "metadata": {},
   "source": [
    "- We plot the total WSSD of each K with the number of clusters (K).\n",
    "- **Side note**: We can view the total WSSD `tot.withinss` by using the `glance(fitted_model)` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566182d9-4685-47b8-9bc1-586aa1ba9370",
   "metadata": {},
   "source": [
    "1. To calculate the total WSSD for **variety of K**, we create a data frame with a column nuamed `num_clusters`: `tibble(num_clusters = 1:10)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef048e-dea0-473b-8373-8401e4830fdc",
   "metadata": {},
   "source": [
    "2. Then we create the model specification again: specifying we want to **tune** the `num_clusters`\n",
    "- `k_means(num_clusters = tune())`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137858dc-c6c3-43fd-81f2-034c2a24db91",
   "metadata": {},
   "source": [
    "3. We combine the recipe and new model specification in a workflow()\n",
    "- In the workflow(), we have to add:\n",
    "- `tune_cluster(resamples = apparent(original data), grid = kvaltibble)`\n",
    "- This is to run K-means on each of the different settings of `num_clusters`\n",
    "- The `grid` argument controls which Ks we want to try\n",
    "- The `resamples = apparent(original_data)` tell K-means to run on the **whole** data set for each value of the num_clusters\n",
    "- lastly, use the `collect_metrics()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f4e204-875d-487d-b682-674e9f7844ff",
   "metadata": {},
   "source": [
    "4. To get the total WSSD results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee90e8-e03e-49a9-8a58-ca18c1d224ed",
   "metadata": {},
   "source": [
    "- total WSSD corresponds to `mean` column, and `.metric == \"sse_within_total\"`\n",
    "- We should also rename the `mean` column to `total_WSSD` by\n",
    "- `mutate(total_WSSD = mean)`\n",
    "- then we select for `num_clusters, total_WSSD`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa36da-f014-4233-bcf7-a4123ffc1ce6",
   "metadata": {},
   "source": [
    "5. Lastly that we have the total_WSSD of each num_cluster, we can make a `geom_point`, `geom_line` plot\n",
    "\n",
    "- find the \"elbow\" for the K value to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e068dc-7c25-4cc3-9170-e2dd934ba239",
   "metadata": {},
   "source": [
    "**How do we prevent having UNLUCKY initialization?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f07f0-6043-4f1c-8ac5-ed1b97854a3d",
   "metadata": {},
   "source": [
    "- We use the argument `nstart = 10` in the model specification:\n",
    "- `set_engine(\"stats\", nstart = 10)`\n",
    "- Now we run the new model specification, K-means clustering will perform 10 times initial starts for each K value.\n",
    "- `collect_metrics()` will pick the best clustering of the 10 random starts (lowest total_WSSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251694e-3cb6-471b-ac9d-51731d357ea9",
   "metadata": {},
   "source": [
    "**The more nstart the better analysis, but takes a much longer time** Balance is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff8f35-0172-4694-b8ea-9ed900b01002",
   "metadata": {},
   "source": [
    "**LO 5: Disadvantages of multi-dimensional data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0be49e-2d1b-480f-a2e1-57067f230575",
   "metadata": {},
   "source": [
    "- makes it very difficult to interpret the different properties of each clusters\n",
    "- Since we want to visualize the clusters, but we **cannot** visualize them in a higher dimensional space, it becomes **difficult** to **assess the accuracy of our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28b4ec-ddf0-46ac-ac7a-7f8ce27b6284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
